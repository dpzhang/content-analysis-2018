{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 - Information Extraction\n",
    "\n",
    "\n",
    "This week, we move from arbitrary textual classification to the use of computation and linguistic models to parse precise claims from documents. Rather than focusing on simply the *ideas* in a corpus, here we focus on understanding and extracting its precise *claims*. This process involves a sequential pipeline of classifying and structuring tokens from text, each of which generates potentially useful data for the content analyst. Steps in this process, which we examine in this notebook, include: 1) tagging words by their part of speech (POS) to reveal the linguistic role they play in the sentence (e.g., Verb, Noun, Adjective, etc.); 2) tagging words as named entities (NER) such as places or organizations; 3) structuring or \"parsing\" sentences into nested phrases that are local to, describe or depend on one another; and 4) extracting informational claims from those phrases, like the Subject-Verb-Object (SVO) triples we extract here. While much of this can be done directly in the python package NLTK that we introduced in week 2, here we use NLTK bindings to the Stanford NLP group's open software, written in Java. Try typing a sentence into the online version [here](http://nlp.stanford.edu:8080/corenlp/) to get a sense of its potential. It is superior in performance to NLTK's implementations, but takes time to run, and so for these exercises we will parse and extract information for a very small text corpus. Of course, for final projects that draw on these tools, we encourage you to install the software on your own machines or shared servers at the university (RCC, SSRC) in order to perform these operations on much more text. \n",
    "\n",
    "For this notebook we will be using the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud #pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#For NLP\n",
    "import nltk\n",
    "\n",
    "import numpy as np #For arrays\n",
    "import pandas #Gives us DataFrames\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import seaborn #Makes the graphics look nicer\n",
    "\n",
    "#Displays the graphs\n",
    "import graphviz #You also need to install the command line graphviz\n",
    "\n",
    "#These are from the standard library\n",
    "import os.path\n",
    "import zipfile\n",
    "import subprocess\n",
    "import io\n",
    "import tempfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to run this _once_ to download everything, you will also need [Java 1.8+](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) if you are using Windows or MacOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting downloads, this will take 5-10 minutes\n",
      "../stanford-NLP/core already exists, skipping download\n",
      "../stanford-NLP/postagger already exists, skipping download\n",
      "../stanford-NLP/parser already exists, skipping download\n",
      "../stanford-NLP/ner already exists, skipping download\n",
      "Done setting up the Stanford NLP collection\n"
     ]
    }
   ],
   "source": [
    "lucem_illud.setupStanfordNLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to have stanford-NLP setup before importing, so we are doing the import here. IF you have stanford-NLP working, you can import at the beginning like you would with any other library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lucem_illud.stanford as stanford"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Information Extraction is a module packaged within the Stanford Core NLP package, but it is not yet supported by `nltk`. As a result, we have defining our own `lucem_illud` function that runs the Stanford Core NLP java code right here. For other projects, it is often useful to use Java or other programs (in C, C++) within a python workflow, and this is an example. `stanford.openIE()` takes in a string or list of strings and then produces as output all the subject, verb, object (SVO) triples Stanford Corenlp can find, as a DataFrame. You can do this through links to the Stanford Core NLP project that we provide here, or play with their interface directly (in the penultimate cell of this notebook), which produces data in \"pretty graphics\" like this example parsing of the first sentence in the \"Shooting of Trayvon Martin\" Wikipedia article:\n",
    "\n",
    "![Output 1](../data/stanford_core1.png)\n",
    "![Output 2](../data/stanford_core2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will illustrate these tools on some *very* short examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I saw the elephant in my pajamas.\n",
      "The quick brown fox jumped over the lazy dog.\n",
      "While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.\n",
      "Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.\n",
      "Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo\n"
     ]
    }
   ],
   "source": [
    "text = ['I saw the elephant in my pajamas.', 'The quick brown fox jumped over the lazy dog.', 'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.', 'Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.', 'Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo']\n",
    "tokenized_text = [nltk.word_tokenize(t) for t in text]\n",
    "print('\\n'.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech (POS) tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In POS tagging, we classify each word by its semantic role in a sentence. The Stanford POS tagger uses the [Penn Treebank tag set]('http://repository.upenn.edu/cgi/viewcontent.cgi?article=1603&context=cis_reports') to POS tag words from input sentences. As discussed in the second assignment, this is a relatively precise tagset, which allows more informative tags, and also more opportunities to err :-).\n",
    "\n",
    "|#. |Tag |Description |\n",
    "|---|----|------------|\n",
    "|1.\t|CC\t|Coordinating conjunction\n",
    "|2.\t|CD\t|Cardinal number\n",
    "|3.\t|DT\t|Determiner\n",
    "|4.\t|EX\t|Existential there\n",
    "|5.\t|FW\t|Foreign word\n",
    "|6.\t|IN\t|Preposition or subordinating conjunction\n",
    "|7.\t|JJ\t|Adjective\n",
    "|8.\t|JJR|\tAdjective, comparative\n",
    "|9.\t|JJS|\tAdjective, superlative\n",
    "|10.|\tLS\t|List item marker\n",
    "|11.|\tMD\t|Modal\n",
    "|12.|\tNN\t|Noun, singular or mass\n",
    "|13.|\tNNS\t|Noun, plural\n",
    "|14.|\tNNP\t|Proper noun, singular\n",
    "|15.|\tNNPS|\tProper noun, plural\n",
    "|16.|\tPDT\t|Predeterminer\n",
    "|17.|\tPOS\t|Possessive ending\n",
    "|18.|\tPRP\t|Personal pronoun\n",
    "|19.|\tPRP\\$|\tPossessive pronoun\n",
    "|20.|\tRB\t|Adverb\n",
    "|21.|\tRBR\t|Adverb, comparative\n",
    "|22.|\tRBS\t|Adverb, superlative\n",
    "|23.|\tRP\t|Particle\n",
    "|24.|\tSYM\t|Symbol\n",
    "|25.|\tTO\t|to\n",
    "|26.|\tUH\t|Interjection\n",
    "|27.|\tVB\t|Verb, base form\n",
    "|28.|\tVBD\t|Verb, past tense\n",
    "|29.|\tVBG\t|Verb, gerund or present participle\n",
    "|30.|\tVBN\t|Verb, past participle\n",
    "|31.|\tVBP\t|Verb, non-3rd person singular present\n",
    "|32.|\tVBZ\t|Verb, 3rd person singular present\n",
    "|33.|\tWDT\t|Wh-determiner\n",
    "|34.|\tWP\t|Wh-pronoun\n",
    "|35.|\tWP$\t|Possessive wh-pronoun\n",
    "|36.|\tWRB\t|Wh-adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('I', 'PRP'), ('saw', 'VBD'), ('the', 'DT'), ('elephant', 'NN'), ('in', 'IN'), ('my', 'PRP$'), ('pajamas', 'NNS'), ('.', '.')], [('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ('jumped', 'VBD'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')], [('While', 'IN'), ('in', 'IN'), ('France', 'NNP'), (',', ','), ('Christine', 'NNP'), ('Lagarde', 'NNP'), ('discussed', 'VBD'), ('short-term', 'JJ'), ('stimulus', 'NN'), ('efforts', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('recent', 'JJ'), ('interview', 'NN'), ('with', 'IN'), ('the', 'DT'), ('Wall', 'NNP'), ('Street', 'NNP'), ('Journal', 'NNP'), ('.', '.')], [('Trayvon', 'NNP'), ('Benjamin', 'NNP'), ('Martin', 'NNP'), ('was', 'VBD'), ('an', 'DT'), ('African', 'NNP'), ('American', 'NNP'), ('from', 'IN'), ('Miami', 'NNP'), ('Gardens', 'NNP'), (',', ','), ('Florida', 'NNP'), (',', ','), ('who', 'WP'), (',', ','), ('at', 'IN'), ('17', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('was', 'VBD'), ('fatally', 'RB'), ('shot', 'VBN'), ('by', 'IN'), ('George', 'NNP'), ('Zimmerman', 'NNP'), (',', ','), ('a', 'DT'), ('neighborhood', 'NN'), ('watch', 'NN'), ('volunteer', 'NN'), (',', ','), ('in', 'IN'), ('Sanford', 'NNP'), (',', ','), ('Florida', 'NNP'), ('.', '.')], [('Buffalo', 'NNP'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "pos_sents = stanford.postTagger.tag_sents(tokenized_text)\n",
    "print(pos_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks quite good. Now we will try POS tagging with a somewhat larger corpus. We consider a few of the top posts from the reddit data we used last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redditDF = pandas.read_csv('../data/reddit.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>over_18</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>guitarsdontdance</td>\n",
       "      <td>False</td>\n",
       "      <td>14089</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>So my story starts on what was a normal day ta...</td>\n",
       "      <td>\"Don't bother sending a tech, I'll be dead by ...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SECGaz</td>\n",
       "      <td>False</td>\n",
       "      <td>13724</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>&gt; $Me  - Hello, IT.   &gt; $Usr - Hi, I am still ...</td>\n",
       "      <td>Hi, I am still off sick but I am not.</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clickity_clickity</td>\n",
       "      <td>False</td>\n",
       "      <td>13404</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>[Part 1](http://www.reddit.com/r/talesfromtech...</td>\n",
       "      <td>Jack, the Worst End User, Part 4</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheDroolinFool</td>\n",
       "      <td>False</td>\n",
       "      <td>13152</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>Another tale from the out of hours IT desk... ...</td>\n",
       "      <td>\"I need you to fix Google Bing immediately!\"</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goldie-gold</td>\n",
       "      <td>False</td>\n",
       "      <td>12650</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>This just happened...  So, I had a laptop syst...</td>\n",
       "      <td>Engineer is doing drugs!! No. No they aren't.</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Raitaro</td>\n",
       "      <td>False</td>\n",
       "      <td>12372</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>I work Helpdesk for a retail store chain in th...</td>\n",
       "      <td>I'm pretty sure I knocked a user out from near...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sfsdfd</td>\n",
       "      <td>False</td>\n",
       "      <td>11295</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>I witnessed this astounding IT meltdown around...</td>\n",
       "      <td>Company-wide email + 30,000 employees + auto-r...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bombadils</td>\n",
       "      <td>False</td>\n",
       "      <td>10528</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>First post in quite some time! I work at a loc...</td>\n",
       "      <td>OK, now the password is 'D35p41r'</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>brenkelieshere</td>\n",
       "      <td>False</td>\n",
       "      <td>9448</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>Last year, Help Desk got a call from a user co...</td>\n",
       "      <td>How to fix a laptop that won't boot in under a...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CopperD</td>\n",
       "      <td>False</td>\n",
       "      <td>9359</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>A call comes in, a user reports her keyboard i...</td>\n",
       "      <td>nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Theallmightyadmin</td>\n",
       "      <td>False</td>\n",
       "      <td>9293</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>I was working for a large warehouse and custo...</td>\n",
       "      <td>Get the scripts before you fire your IT</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author  over_18  score                subreddit  \\\n",
       "0    guitarsdontdance    False  14089  Tales From Tech Support   \n",
       "1              SECGaz    False  13724  Tales From Tech Support   \n",
       "2   Clickity_clickity    False  13404  Tales From Tech Support   \n",
       "3      TheDroolinFool    False  13152  Tales From Tech Support   \n",
       "4         goldie-gold    False  12650  Tales From Tech Support   \n",
       "5             Raitaro    False  12372  Tales From Tech Support   \n",
       "6              sfsdfd    False  11295  Tales From Tech Support   \n",
       "7           Bombadils    False  10528  Tales From Tech Support   \n",
       "8      brenkelieshere    False   9448  Tales From Tech Support   \n",
       "9             CopperD    False   9359  Tales From Tech Support   \n",
       "10  Theallmightyadmin    False   9293  Tales From Tech Support   \n",
       "\n",
       "                                                 text  \\\n",
       "0   So my story starts on what was a normal day ta...   \n",
       "1   > $Me  - Hello, IT.   > $Usr - Hi, I am still ...   \n",
       "2   [Part 1](http://www.reddit.com/r/talesfromtech...   \n",
       "3   Another tale from the out of hours IT desk... ...   \n",
       "4   This just happened...  So, I had a laptop syst...   \n",
       "5   I work Helpdesk for a retail store chain in th...   \n",
       "6   I witnessed this astounding IT meltdown around...   \n",
       "7   First post in quite some time! I work at a loc...   \n",
       "8   Last year, Help Desk got a call from a user co...   \n",
       "9   A call comes in, a user reports her keyboard i...   \n",
       "10   I was working for a large warehouse and custo...   \n",
       "\n",
       "                                                title  \\\n",
       "0   \"Don't bother sending a tech, I'll be dead by ...   \n",
       "1               Hi, I am still off sick but I am not.   \n",
       "2                    Jack, the Worst End User, Part 4   \n",
       "3        \"I need you to fix Google Bing immediately!\"   \n",
       "4       Engineer is doing drugs!! No. No they aren't.   \n",
       "5   I'm pretty sure I knocked a user out from near...   \n",
       "6   Company-wide email + 30,000 employees + auto-r...   \n",
       "7                   OK, now the password is 'D35p41r'   \n",
       "8   How to fix a laptop that won't boot in under a...   \n",
       "9              nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn   \n",
       "10            Get the scripts before you fire your IT   \n",
       "\n",
       "                                                  url  \n",
       "0   https://www.reddit.com/r/talesfromtechsupport/...  \n",
       "1   https://www.reddit.com/r/talesfromtechsupport/...  \n",
       "2   https://www.reddit.com/r/talesfromtechsupport/...  \n",
       "3   https://www.reddit.com/r/talesfromtechsupport/...  \n",
       "4   https://www.reddit.com/r/talesfromtechsupport/...  \n",
       "5   https://www.reddit.com/r/talesfromtechsupport/...  \n",
       "6   https://www.reddit.com/r/talesfromtechsupport/...  \n",
       "7   https://www.reddit.com/r/talesfromtechsupport/...  \n",
       "8   https://www.reddit.com/r/talesfromtechsupport/...  \n",
       "9   https://www.reddit.com/r/talesfromtechsupport/...  \n",
       "10  https://www.reddit.com/r/talesfromtechsupport/...  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditDF.loc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing the 10 highest scoring posts and tokenizing the sentences. Once again, notice that we aren't going to do any kind of stemming this week (although *semantic* normalization may be performed where we translate synonyms into the same focal word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>over_18</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goldie-gold</td>\n",
       "      <td>False</td>\n",
       "      <td>12650</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>This just happened...  So, I had a laptop syst...</td>\n",
       "      <td>Engineer is doing drugs!! No. No they aren't.</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[This, just, happened, ...], [So, ,, I, had, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheDroolinFool</td>\n",
       "      <td>False</td>\n",
       "      <td>13152</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>Another tale from the out of hours IT desk... ...</td>\n",
       "      <td>\"I need you to fix Google Bing immediately!\"</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[Another, tale, from, the, out, of, hours, IT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clickity_clickity</td>\n",
       "      <td>False</td>\n",
       "      <td>13404</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>[Part 1](http://www.reddit.com/r/talesfromtech...</td>\n",
       "      <td>Jack, the Worst End User, Part 4</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[[, Part, 1, ], (, http, :, //www.reddit.com/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SECGaz</td>\n",
       "      <td>False</td>\n",
       "      <td>13724</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>&gt; $Me  - Hello, IT.   &gt; $Usr - Hi, I am still ...</td>\n",
       "      <td>Hi, I am still off sick but I am not.</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[&gt;, $, Me, -, Hello, ,, IT, .], [&gt;, $, Usr, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>guitarsdontdance</td>\n",
       "      <td>False</td>\n",
       "      <td>14089</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>So my story starts on what was a normal day ta...</td>\n",
       "      <td>\"Don't bother sending a tech, I'll be dead by ...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[So, my, story, starts, on, what, was, a, nor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author  over_18  score                subreddit  \\\n",
       "4        goldie-gold    False  12650  Tales From Tech Support   \n",
       "3     TheDroolinFool    False  13152  Tales From Tech Support   \n",
       "2  Clickity_clickity    False  13404  Tales From Tech Support   \n",
       "1             SECGaz    False  13724  Tales From Tech Support   \n",
       "0   guitarsdontdance    False  14089  Tales From Tech Support   \n",
       "\n",
       "                                                text  \\\n",
       "4  This just happened...  So, I had a laptop syst...   \n",
       "3  Another tale from the out of hours IT desk... ...   \n",
       "2  [Part 1](http://www.reddit.com/r/talesfromtech...   \n",
       "1  > $Me  - Hello, IT.   > $Usr - Hi, I am still ...   \n",
       "0  So my story starts on what was a normal day ta...   \n",
       "\n",
       "                                               title  \\\n",
       "4      Engineer is doing drugs!! No. No they aren't.   \n",
       "3       \"I need you to fix Google Bing immediately!\"   \n",
       "2                   Jack, the Worst End User, Part 4   \n",
       "1              Hi, I am still off sick but I am not.   \n",
       "0  \"Don't bother sending a tech, I'll be dead by ...   \n",
       "\n",
       "                                                 url  \\\n",
       "4  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "3  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "2  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "1  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "0  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "\n",
       "                                           sentences  \n",
       "4  [[This, just, happened, ...], [So, ,, I, had, ...  \n",
       "3  [[Another, tale, from, the, out, of, hours, IT...  \n",
       "2  [[[, Part, 1, ], (, http, :, //www.reddit.com/...  \n",
       "1  [[>, $, Me, -, Hello, ,, IT, .], [>, $, Usr, -...  \n",
       "0  [[So, my, story, starts, on, what, was, a, nor...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores = redditDF.sort_values('score')[-10:]\n",
    "redditTopScores['sentences'] = redditTopScores['text'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n",
    "redditTopScores.index = range(len(redditTopScores) - 1, -1,-1) #Reindex to make things nice in the future\n",
    "redditTopScores[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redditTopScores['POS_sents'] = redditTopScores['sentences'].apply(lambda x: stanford.postTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    [[(Last, JJ), (year, NN), (,, ,), (Help, NN), ...\n",
       "8    [[(First, JJ), (post, NN), (in, IN), (quite, R...\n",
       "7    [[([, NNP), (Original, NNP), (Post, NNP), (], ...\n",
       "6    [[(I, PRP), (witnessed, VBD), (this, DT), (ast...\n",
       "5    [[(I, PRP), (work, VBP), (Helpdesk, NNP), (for...\n",
       "4    [[(This, DT), (just, RB), (happened, VBN), (.....\n",
       "3    [[(Another, DT), (tale, NN), (from, IN), (the,...\n",
       "2    [[([, NNP), (Part, NNP), (1, CD), (], FW), ((,...\n",
       "1    [[(>, JJR), ($, $), (Me, PRP), (-, :), (Hello,...\n",
       "0    [[(So, RB), (my, PRP$), (story, NN), (starts, ...\n",
       "Name: POS_sents, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores['POS_sents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And count the number of `NN` (nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('password', 21),\n",
       " ('(', 19),\n",
       " ('time', 14),\n",
       " (')', 14),\n",
       " ('lot', 12),\n",
       " ('computer', 12),\n",
       " ('email', 11),\n",
       " ('life', 11),\n",
       " ('**Genius**', 10),\n",
       " ('system', 9),\n",
       " ('message', 9),\n",
       " ('**Me**', 9),\n",
       " ('day', 9),\n",
       " ('office', 8),\n",
       " ('laptop', 8),\n",
       " ('part', 8),\n",
       " ('story', 8),\n",
       " ('today', 8),\n",
       " ('call', 8),\n",
       " ('user', 7)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countTarget = 'NN'\n",
    "targetCounts = {}\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the number of top verbs (`VB`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 18),\n",
       " ('have', 17),\n",
       " ('get', 14),\n",
       " ('do', 11),\n",
       " ('change', 9),\n",
       " ('make', 8),\n",
       " ('know', 7),\n",
       " ('say', 7),\n",
       " ('tell', 6),\n",
       " ('send', 6),\n",
       " ('look', 6),\n",
       " ('help', 6),\n",
       " ('go', 5),\n",
       " ('use', 4),\n",
       " ('want', 4),\n",
       " ('thank', 4),\n",
       " ('take', 4),\n",
       " ('work', 4),\n",
       " ('call', 4),\n",
       " ('open', 4)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countTarget = 'VB'\n",
    "targetCounts = {}\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the adjectives that modify the word, \"computer\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'own', 'unrestricted'}\n"
     ]
    }
   ],
   "source": [
    "NTarget = 'JJ'\n",
    "Word = 'computer'\n",
    "NResults = set()\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for (ent1, kind1),(ent2,kind2) in zip(sentence[:-1], sentence[1:]):\n",
    "            if (kind1,ent2.lower())==(NTarget,Word):\n",
    "                NResults.add(ent1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "print(NResults)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating POS tagger\n",
    "\n",
    "We can check the POS tagger by running it on a manually tagged corpus and identifying a reasonable error metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeBank = nltk.corpus.treebank\n",
    "treeBank.tagged_sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeBank.sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stanfordTags = stanford.postTagger.tag_sents(treeBank.sents()[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compare the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Dutch  \tStanford: JJ\tTreebank: NNP\n",
      "Word: publishing  \tStanford: NN\tTreebank: VBG\n",
      "Word: used  \tStanford: VBD\tTreebank: VBN\n",
      "Word: more  \tStanford: JJR\tTreebank: RBR\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: later  \tStanford: RB\tTreebank: JJ\n",
      "Word: New  \tStanford: NNP\tTreebank: JJ\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: more  \tStanford: JJR\tTreebank: RBR\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: replaced  \tStanford: VBD\tTreebank: VBN\n",
      "Word: more  \tStanford: JJR\tTreebank: JJ\n",
      "Word: expected  \tStanford: VBD\tTreebank: VBN\n",
      "Word: study  \tStanford: VBD\tTreebank: VBP\n",
      "Word: studied  \tStanford: VBD\tTreebank: VBN\n",
      "Word: industrialized  \tStanford: JJ\tTreebank: VBN\n",
      "Word: Lorillard  \tStanford: NNP\tTreebank: NN\n",
      "Word: found  \tStanford: VBD\tTreebank: VBN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: rejected  \tStanford: VBD\tTreebank: VBN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: poured  \tStanford: VBN\tTreebank: VBD\n",
      "Word: in  \tStanford: IN\tTreebank: RP\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "The Precision is 96.547%\n"
     ]
    }
   ],
   "source": [
    "NumDiffs = 0\n",
    "for sentIndex in range(len(stanfordTags)):\n",
    "    for wordIndex in range(len(stanfordTags[sentIndex])):\n",
    "        if stanfordTags[sentIndex][wordIndex][1] != treeBank.tagged_sents()[sentIndex][wordIndex][1]:\n",
    "            if treeBank.tagged_sents()[sentIndex][wordIndex][1] != '-NONE-':\n",
    "                print(\"Word: {}  \\tStanford: {}\\tTreebank: {}\".format(stanfordTags[sentIndex][wordIndex][0], stanfordTags[sentIndex][wordIndex][1], treeBank.tagged_sents()[sentIndex][wordIndex][1]))\n",
    "                NumDiffs += 1\n",
    "total = sum([len(s) for s in stanfordTags])\n",
    "print(\"The Precision is {:.3f}%\".format((total-NumDiffs)/total * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that the stanford POS tagger is quite good. Nevertheless, for a 20 word sentence, we only have a 66% chance ($1-.96^{20}$) of tagging (and later parsing) it correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 1*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform POS tagging on a meaningful (but modest) subset of a corpus associated with your final project. Examine the list of words associated with at least three different parts of speech. Consider conditional frequencies (e.g., adjectives associated with nouns of interest or adverbs with verbs of interest). What do these distributions suggest about your corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subset of project data that I am using in this assignment is 200 horror film plots that have showned after 2008 in the United States. The reason I am choosing to study horror film is because I am interested in studying: During the period of the Great Recession, were people more fond of horror films that feature monsters or horror films that feature people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load horror movies data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3280828</td>\n",
       "      <td>'Til Death</td>\n",
       "      <td>2011</td>\n",
       "      <td>As a newlywed mourns the loss of his late wife...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3280848</td>\n",
       "      <td>'Til Death Do Us Part</td>\n",
       "      <td>2011</td>\n",
       "      <td>Niko's a conman who knows his wife is unfaithf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3281056</td>\n",
       "      <td>(AmI) Live</td>\n",
       "      <td>2011</td>\n",
       "      <td>In an interconnected world of intuitive techno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3281283</td>\n",
       "      <td>*67</td>\n",
       "      <td>2011</td>\n",
       "      <td>A group of college students getting stalked by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3281779</td>\n",
       "      <td>...With the Lights Out</td>\n",
       "      <td>2010</td>\n",
       "      <td>Even though Rachel's parents would never appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3281971</td>\n",
       "      <td>00:05'01</td>\n",
       "      <td>2008</td>\n",
       "      <td>A scenic work about nature, human nature, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3282347</td>\n",
       "      <td>1, 2, Z</td>\n",
       "      <td>2011</td>\n",
       "      <td>It's the 50's, and instead of the Communists, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3282410</td>\n",
       "      <td>1-800-Suicide</td>\n",
       "      <td>2009</td>\n",
       "      <td>The flashing red light of the phone blinds you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3282994</td>\n",
       "      <td>100 Feet</td>\n",
       "      <td>2008</td>\n",
       "      <td>After seven years and fifty-two days in prison...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3283596</td>\n",
       "      <td>1013 Briar Lane</td>\n",
       "      <td>2009</td>\n",
       "      <td>In 2008, a real-life mystery began to unfold w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3283866</td>\n",
       "      <td>11-11-11</td>\n",
       "      <td>2011</td>\n",
       "      <td>After the tragic death of his wife and his son...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movie_id                   title  year  \\\n",
       "0    3280828              'Til Death  2011   \n",
       "1    3280848   'Til Death Do Us Part  2011   \n",
       "2    3281056              (AmI) Live  2011   \n",
       "3    3281283                     *67  2011   \n",
       "4    3281779  ...With the Lights Out  2010   \n",
       "5    3281971                00:05'01  2008   \n",
       "6    3282347                 1, 2, Z  2011   \n",
       "7    3282410           1-800-Suicide  2009   \n",
       "8    3282994                100 Feet  2008   \n",
       "9    3283596         1013 Briar Lane  2009   \n",
       "10   3283866                11-11-11  2011   \n",
       "\n",
       "                                                 plot  \n",
       "0   As a newlywed mourns the loss of his late wife...  \n",
       "1   Niko's a conman who knows his wife is unfaithf...  \n",
       "2   In an interconnected world of intuitive techno...  \n",
       "3   A group of college students getting stalked by...  \n",
       "4   Even though Rachel's parents would never appro...  \n",
       "5   A scenic work about nature, human nature, and ...  \n",
       "6   It's the 50's, and instead of the Communists, ...  \n",
       "7   The flashing red light of the phone blinds you...  \n",
       "8   After seven years and fifty-two days in prison...  \n",
       "9   In 2008, a real-life mystery began to unfold w...  \n",
       "10  After the tragic death of his wife and his son...  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horror = pandas.read_csv('../data/horrorPlots.csv') \n",
    "horror.loc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a modest subset of corpus, take a random sample of 100 and reset its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>762</td>\n",
       "      <td>3805678</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>2010</td>\n",
       "      <td>A young girl goes missing during the night and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1115</td>\n",
       "      <td>4160069</td>\n",
       "      <td>Paranormal Incident</td>\n",
       "      <td>2011</td>\n",
       "      <td>The infamous Odenbrook Sanitarium closed after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1282</td>\n",
       "      <td>4272877</td>\n",
       "      <td>Sanctuary</td>\n",
       "      <td>2008</td>\n",
       "      <td>Two sisters have been hiding for over a year. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1259</td>\n",
       "      <td>4257378</td>\n",
       "      <td>Rose's Fable</td>\n",
       "      <td>2008</td>\n",
       "      <td>After her parents passed away, Rose ('AnnaLaur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1746</td>\n",
       "      <td>4506289</td>\n",
       "      <td>The Raven</td>\n",
       "      <td>2010</td>\n",
       "      <td>This short film brings a new interpretation of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>829</td>\n",
       "      <td>3849591</td>\n",
       "      <td>It's Alive</td>\n",
       "      <td>2008</td>\n",
       "      <td>Pregnant college student Lenore Harker leaves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1883</td>\n",
       "      <td>4571401</td>\n",
       "      <td>Tragic</td>\n",
       "      <td>2009</td>\n",
       "      <td>Alfonso and Lucia Labella are expecting their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1616</td>\n",
       "      <td>4458959</td>\n",
       "      <td>The Haunting of Molly Hartley</td>\n",
       "      <td>2008</td>\n",
       "      <td>The bright atheist teenager Molly Hartley move...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1051</td>\n",
       "      <td>4102974</td>\n",
       "      <td>Nine Minute Love Song</td>\n",
       "      <td>2009</td>\n",
       "      <td>Claire is an eighteen year old girl from rural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3283596</td>\n",
       "      <td>1013 Briar Lane</td>\n",
       "      <td>2009</td>\n",
       "      <td>In 2008, a real-life mystery began to unfold w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  movie_id                          title  year  \\\n",
       "0    762   3805678                     Huntsville  2010   \n",
       "1   1115   4160069            Paranormal Incident  2011   \n",
       "2   1282   4272877                      Sanctuary  2008   \n",
       "3   1259   4257378                   Rose's Fable  2008   \n",
       "4   1746   4506289                      The Raven  2010   \n",
       "5    829   3849591                     It's Alive  2008   \n",
       "6   1883   4571401                         Tragic  2009   \n",
       "7   1616   4458959  The Haunting of Molly Hartley  2008   \n",
       "8   1051   4102974          Nine Minute Love Song  2009   \n",
       "9      9   3283596                1013 Briar Lane  2009   \n",
       "\n",
       "                                                plot  \n",
       "0  A young girl goes missing during the night and...  \n",
       "1  The infamous Odenbrook Sanitarium closed after...  \n",
       "2  Two sisters have been hiding for over a year. ...  \n",
       "3  After her parents passed away, Rose ('AnnaLaur...  \n",
       "4  This short film brings a new interpretation of...  \n",
       "5  Pregnant college student Lenore Harker leaves ...  \n",
       "6  Alfonso and Lucia Labella are expecting their ...  \n",
       "7  The bright atheist teenager Molly Hartley move...  \n",
       "8  Claire is an eighteen year old girl from rural...  \n",
       "9  In 2008, a real-life mystery began to unfold w...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horrorDF = horror.sample(500).reset_index()\n",
    "horrorDF.iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the sentences                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>plot</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>762</td>\n",
       "      <td>3805678</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>2010</td>\n",
       "      <td>A young girl goes missing during the night and...</td>\n",
       "      <td>[[A, young, girl, goes, missing, during, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1115</td>\n",
       "      <td>4160069</td>\n",
       "      <td>Paranormal Incident</td>\n",
       "      <td>2011</td>\n",
       "      <td>The infamous Odenbrook Sanitarium closed after...</td>\n",
       "      <td>[[The, infamous, Odenbrook, Sanitarium, closed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1282</td>\n",
       "      <td>4272877</td>\n",
       "      <td>Sanctuary</td>\n",
       "      <td>2008</td>\n",
       "      <td>Two sisters have been hiding for over a year. ...</td>\n",
       "      <td>[[Two, sisters, have, been, hiding, for, over,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1259</td>\n",
       "      <td>4257378</td>\n",
       "      <td>Rose's Fable</td>\n",
       "      <td>2008</td>\n",
       "      <td>After her parents passed away, Rose ('AnnaLaur...</td>\n",
       "      <td>[[After, her, parents, passed, away, ,, Rose, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1746</td>\n",
       "      <td>4506289</td>\n",
       "      <td>The Raven</td>\n",
       "      <td>2010</td>\n",
       "      <td>This short film brings a new interpretation of...</td>\n",
       "      <td>[[This, short, film, brings, a, new, interpret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>829</td>\n",
       "      <td>3849591</td>\n",
       "      <td>It's Alive</td>\n",
       "      <td>2008</td>\n",
       "      <td>Pregnant college student Lenore Harker leaves ...</td>\n",
       "      <td>[[Pregnant, college, student, Lenore, Harker, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1883</td>\n",
       "      <td>4571401</td>\n",
       "      <td>Tragic</td>\n",
       "      <td>2009</td>\n",
       "      <td>Alfonso and Lucia Labella are expecting their ...</td>\n",
       "      <td>[[Alfonso, and, Lucia, Labella, are, expecting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1616</td>\n",
       "      <td>4458959</td>\n",
       "      <td>The Haunting of Molly Hartley</td>\n",
       "      <td>2008</td>\n",
       "      <td>The bright atheist teenager Molly Hartley move...</td>\n",
       "      <td>[[The, bright, atheist, teenager, Molly, Hartl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1051</td>\n",
       "      <td>4102974</td>\n",
       "      <td>Nine Minute Love Song</td>\n",
       "      <td>2009</td>\n",
       "      <td>Claire is an eighteen year old girl from rural...</td>\n",
       "      <td>[[Claire, is, an, eighteen, year, old, girl, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3283596</td>\n",
       "      <td>1013 Briar Lane</td>\n",
       "      <td>2009</td>\n",
       "      <td>In 2008, a real-life mystery began to unfold w...</td>\n",
       "      <td>[[In, 2008, ,, a, real-life, mystery, began, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  movie_id                          title  year  \\\n",
       "0    762   3805678                     Huntsville  2010   \n",
       "1   1115   4160069            Paranormal Incident  2011   \n",
       "2   1282   4272877                      Sanctuary  2008   \n",
       "3   1259   4257378                   Rose's Fable  2008   \n",
       "4   1746   4506289                      The Raven  2010   \n",
       "5    829   3849591                     It's Alive  2008   \n",
       "6   1883   4571401                         Tragic  2009   \n",
       "7   1616   4458959  The Haunting of Molly Hartley  2008   \n",
       "8   1051   4102974          Nine Minute Love Song  2009   \n",
       "9      9   3283596                1013 Briar Lane  2009   \n",
       "\n",
       "                                                plot  \\\n",
       "0  A young girl goes missing during the night and...   \n",
       "1  The infamous Odenbrook Sanitarium closed after...   \n",
       "2  Two sisters have been hiding for over a year. ...   \n",
       "3  After her parents passed away, Rose ('AnnaLaur...   \n",
       "4  This short film brings a new interpretation of...   \n",
       "5  Pregnant college student Lenore Harker leaves ...   \n",
       "6  Alfonso and Lucia Labella are expecting their ...   \n",
       "7  The bright atheist teenager Molly Hartley move...   \n",
       "8  Claire is an eighteen year old girl from rural...   \n",
       "9  In 2008, a real-life mystery began to unfold w...   \n",
       "\n",
       "                                           sentences  \n",
       "0  [[A, young, girl, goes, missing, during, the, ...  \n",
       "1  [[The, infamous, Odenbrook, Sanitarium, closed...  \n",
       "2  [[Two, sisters, have, been, hiding, for, over,...  \n",
       "3  [[After, her, parents, passed, away, ,, Rose, ...  \n",
       "4  [[This, short, film, brings, a, new, interpret...  \n",
       "5  [[Pregnant, college, student, Lenore, Harker, ...  \n",
       "6  [[Alfonso, and, Lucia, Labella, are, expecting...  \n",
       "7  [[The, bright, atheist, teenager, Molly, Hartl...  \n",
       "8  [[Claire, is, an, eighteen, year, old, girl, f...  \n",
       "9  [[In, 2008, ,, a, real-life, mystery, began, t...  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horrorDF['sentences'] = horrorDF['plot'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n",
    "horrorDF.iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Part-of-Speech (POS) tagging of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>plot</th>\n",
       "      <th>sentences</th>\n",
       "      <th>POS_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>762</td>\n",
       "      <td>3805678</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>2010</td>\n",
       "      <td>A young girl goes missing during the night and...</td>\n",
       "      <td>[[A, young, girl, goes, missing, during, the, ...</td>\n",
       "      <td>[[(A, DT), (young, JJ), (girl, NN), (goes, VBZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1115</td>\n",
       "      <td>4160069</td>\n",
       "      <td>Paranormal Incident</td>\n",
       "      <td>2011</td>\n",
       "      <td>The infamous Odenbrook Sanitarium closed after...</td>\n",
       "      <td>[[The, infamous, Odenbrook, Sanitarium, closed...</td>\n",
       "      <td>[[(The, DT), (infamous, JJ), (Odenbrook, NNP),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1282</td>\n",
       "      <td>4272877</td>\n",
       "      <td>Sanctuary</td>\n",
       "      <td>2008</td>\n",
       "      <td>Two sisters have been hiding for over a year. ...</td>\n",
       "      <td>[[Two, sisters, have, been, hiding, for, over,...</td>\n",
       "      <td>[[(Two, CD), (sisters, NNS), (have, VBP), (bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1259</td>\n",
       "      <td>4257378</td>\n",
       "      <td>Rose's Fable</td>\n",
       "      <td>2008</td>\n",
       "      <td>After her parents passed away, Rose ('AnnaLaur...</td>\n",
       "      <td>[[After, her, parents, passed, away, ,, Rose, ...</td>\n",
       "      <td>[[(After, IN), (her, PRP$), (parents, NNS), (p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1746</td>\n",
       "      <td>4506289</td>\n",
       "      <td>The Raven</td>\n",
       "      <td>2010</td>\n",
       "      <td>This short film brings a new interpretation of...</td>\n",
       "      <td>[[This, short, film, brings, a, new, interpret...</td>\n",
       "      <td>[[(This, DT), (short, JJ), (film, NN), (brings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>829</td>\n",
       "      <td>3849591</td>\n",
       "      <td>It's Alive</td>\n",
       "      <td>2008</td>\n",
       "      <td>Pregnant college student Lenore Harker leaves ...</td>\n",
       "      <td>[[Pregnant, college, student, Lenore, Harker, ...</td>\n",
       "      <td>[[(Pregnant, JJ), (college, NN), (student, NN)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1883</td>\n",
       "      <td>4571401</td>\n",
       "      <td>Tragic</td>\n",
       "      <td>2009</td>\n",
       "      <td>Alfonso and Lucia Labella are expecting their ...</td>\n",
       "      <td>[[Alfonso, and, Lucia, Labella, are, expecting...</td>\n",
       "      <td>[[(Alfonso, NNP), (and, CC), (Lucia, NNP), (La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1616</td>\n",
       "      <td>4458959</td>\n",
       "      <td>The Haunting of Molly Hartley</td>\n",
       "      <td>2008</td>\n",
       "      <td>The bright atheist teenager Molly Hartley move...</td>\n",
       "      <td>[[The, bright, atheist, teenager, Molly, Hartl...</td>\n",
       "      <td>[[(The, DT), (bright, JJ), (atheist, NN), (tee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1051</td>\n",
       "      <td>4102974</td>\n",
       "      <td>Nine Minute Love Song</td>\n",
       "      <td>2009</td>\n",
       "      <td>Claire is an eighteen year old girl from rural...</td>\n",
       "      <td>[[Claire, is, an, eighteen, year, old, girl, f...</td>\n",
       "      <td>[[(Claire, NNP), (is, VBZ), (an, DT), (eightee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3283596</td>\n",
       "      <td>1013 Briar Lane</td>\n",
       "      <td>2009</td>\n",
       "      <td>In 2008, a real-life mystery began to unfold w...</td>\n",
       "      <td>[[In, 2008, ,, a, real-life, mystery, began, t...</td>\n",
       "      <td>[[(In, IN), (2008, CD), (,, ,), (a, DT), (real...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  movie_id                          title  year  \\\n",
       "0    762   3805678                     Huntsville  2010   \n",
       "1   1115   4160069            Paranormal Incident  2011   \n",
       "2   1282   4272877                      Sanctuary  2008   \n",
       "3   1259   4257378                   Rose's Fable  2008   \n",
       "4   1746   4506289                      The Raven  2010   \n",
       "5    829   3849591                     It's Alive  2008   \n",
       "6   1883   4571401                         Tragic  2009   \n",
       "7   1616   4458959  The Haunting of Molly Hartley  2008   \n",
       "8   1051   4102974          Nine Minute Love Song  2009   \n",
       "9      9   3283596                1013 Briar Lane  2009   \n",
       "\n",
       "                                                plot  \\\n",
       "0  A young girl goes missing during the night and...   \n",
       "1  The infamous Odenbrook Sanitarium closed after...   \n",
       "2  Two sisters have been hiding for over a year. ...   \n",
       "3  After her parents passed away, Rose ('AnnaLaur...   \n",
       "4  This short film brings a new interpretation of...   \n",
       "5  Pregnant college student Lenore Harker leaves ...   \n",
       "6  Alfonso and Lucia Labella are expecting their ...   \n",
       "7  The bright atheist teenager Molly Hartley move...   \n",
       "8  Claire is an eighteen year old girl from rural...   \n",
       "9  In 2008, a real-life mystery began to unfold w...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [[A, young, girl, goes, missing, during, the, ...   \n",
       "1  [[The, infamous, Odenbrook, Sanitarium, closed...   \n",
       "2  [[Two, sisters, have, been, hiding, for, over,...   \n",
       "3  [[After, her, parents, passed, away, ,, Rose, ...   \n",
       "4  [[This, short, film, brings, a, new, interpret...   \n",
       "5  [[Pregnant, college, student, Lenore, Harker, ...   \n",
       "6  [[Alfonso, and, Lucia, Labella, are, expecting...   \n",
       "7  [[The, bright, atheist, teenager, Molly, Hartl...   \n",
       "8  [[Claire, is, an, eighteen, year, old, girl, f...   \n",
       "9  [[In, 2008, ,, a, real-life, mystery, began, t...   \n",
       "\n",
       "                                           POS_sents  \n",
       "0  [[(A, DT), (young, JJ), (girl, NN), (goes, VBZ...  \n",
       "1  [[(The, DT), (infamous, JJ), (Odenbrook, NNP),...  \n",
       "2  [[(Two, CD), (sisters, NNS), (have, VBP), (bee...  \n",
       "3  [[(After, IN), (her, PRP$), (parents, NNS), (p...  \n",
       "4  [[(This, DT), (short, JJ), (film, NN), (brings...  \n",
       "5  [[(Pregnant, JJ), (college, NN), (student, NN)...  \n",
       "6  [[(Alfonso, NNP), (and, CC), (Lucia, NNP), (La...  \n",
       "7  [[(The, DT), (bright, JJ), (atheist, NN), (tee...  \n",
       "8  [[(Claire, NNP), (is, VBZ), (an, DT), (eightee...  \n",
       "9  [[(In, IN), (2008, CD), (,, ,), (a, DT), (real...  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horrorDF['POS_sents'] = horrorDF['sentences'].apply(lambda x: stanford.postTagger.tag_sents(x))\n",
    "horrorDF.iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export file to the data directory just in case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "horrorDF.to_csv('week7Data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the list of words associated with at least three different parts of speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to facilitate examining the list of words, a function called 'countType' is composed which would tag POS of the corpus and count the number of occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countType(countTarget, corpusPOS, topNum):                                  \n",
    "    targetCounts = {}                                                           \n",
    "    for entry in corpusPOS:                                                     \n",
    "        for sentence in entry:                                                  \n",
    "            for ent, kind in sentence:                                          \n",
    "                if kind != countTarget:                                         \n",
    "                    continue                                                    \n",
    "                elif ent in targetCounts:                                       \n",
    "                    targetCounts[ent] += 1                                      \n",
    "                else:                                                           \n",
    "                    targetCounts[ent] = 1                                       \n",
    "    sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "    return sortedTargets[:topNum] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: \"NN\" stands for noun, singular or mass. So after observing the top 20 noun from a corpus of 500 horror film plot summaries, I discovered life to be the noun that top from all nouns. I think this makes sense a lot as phrases including the noun life is numerous and frequently occurs in the films. The next several nouns to be night, man, house. It is interesting to observe that woman, death, family, killer, and friends are also among the top nouns occuring in horror movie plots. I think this is because most of the horror movies occur involving those subject matters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('life', 122),\n",
       " ('night', 104),\n",
       " ('man', 92),\n",
       " ('town', 89),\n",
       " ('film', 89),\n",
       " ('house', 82),\n",
       " ('time', 76),\n",
       " ('story', 69),\n",
       " ('way', 65),\n",
       " ('group', 63),\n",
       " ('death', 63),\n",
       " ('home', 61),\n",
       " ('world', 59),\n",
       " ('family', 56),\n",
       " ('horror', 51),\n",
       " ('day', 50),\n",
       " ('killer', 49),\n",
       " ('woman', 49),\n",
       " ('girl', 44),\n",
       " ('mother', 43)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countType('NN', horrorDF['POS_sents'], 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: \"JJ\" stands for adjectives. So after observing the top 20 adjectives, we could see some common adjectives we would typically expect to see in a horror movie plot, and those adjectives include \"mysterious\", \"dark\", \"strange\", \"dead\", and \"terrifying\". Meanwhile, there are some strange ones, such as \"young\", \"next\", \"short\", \"true\", \"real\", etc. that I could not associate with the actual movie content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('young', 85),\n",
       " ('new', 64),\n",
       " ('old', 49),\n",
       " ('own', 48),\n",
       " ('dark', 45),\n",
       " ('small', 43),\n",
       " ('next', 41),\n",
       " ('local', 41),\n",
       " ('mysterious', 39),\n",
       " ('human', 36),\n",
       " ('other', 36),\n",
       " ('only', 35),\n",
       " ('first', 32),\n",
       " ('strange', 31),\n",
       " ('dead', 31),\n",
       " ('last', 29),\n",
       " ('true', 25),\n",
       " ('evil', 25),\n",
       " ('short', 25),\n",
       " ('real', 23)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countType('JJ', horrorDF['POS_sents'], 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: \"PRP\" stands for personal pronouns. It could be sees that from the 500 horror movie plots, the most frequently used personal pronoun is \"he\", followed by \"they\", and then followed by \"it\" with the last to be \"she\". It is interesting to see that \"he\" is actually the most frequently occurred personal pronouns as it indicates in those 500 sampled horror movies, males are typically the leading characters. From the frequencies of \"he\" and \"she\", we could also deduce that males are more frequently occurring in horror films than females. This gender bias is further validated by the number of occurrences of \"him\" and \"her\" with \"him\" occurring approximately 70 times more than \"her\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('he', 341),\n",
       " ('they', 281),\n",
       " ('it', 200),\n",
       " ('she', 195),\n",
       " ('him', 170),\n",
       " ('them', 110),\n",
       " ('her', 106),\n",
       " ('He', 81),\n",
       " ('you', 67),\n",
       " ('They', 54),\n",
       " ('It', 51),\n",
       " ('She', 37),\n",
       " ('himself', 32),\n",
       " ('herself', 20),\n",
       " ('themselves', 19),\n",
       " ('we', 17),\n",
       " ('I', 14),\n",
       " ('You', 13),\n",
       " ('us', 12),\n",
       " ('itself', 8)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countType('PRP', horrorDF['POS_sents'], 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider conditional frequencies (e.g., adjectives associated with nouns of interest or adverbs with verbs of interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to facilitate examining the conditional frequencies of choice, a function called 'conditionalFreq' is composed which show the conditional frequencies of choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conditionalFreq(NTarget, corpusPOS, Word):                          \n",
    "    NResults = set()                                                            \n",
    "    for entry in corpusPOS:                                                     \n",
    "        for sentence in entry:                                                  \n",
    "            for (ent1, kind1),(ent2,kind2) in zip(sentence[:-1], sentence[1:]): \n",
    "                if (kind1,ent2.lower())==(NTarget,Word):                        \n",
    "                    NResults.add(ent1)                                          \n",
    "                else:                                                           \n",
    "                    continue                                                    \n",
    "    return NResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the effect of this function and the conditional frequency, I tried to see the adjectives associated with \"zombie\". It turns out the those adjectives include \"apocalyptic\", \"half\", and \"unnamed\". Those are all familiar adjectives that we would associate with zombies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apocalyptic',\n",
       " 'bearded',\n",
       " 'corporate',\n",
       " 'few',\n",
       " 'first',\n",
       " 'half',\n",
       " 'individual',\n",
       " 'inevitable',\n",
       " 'modern',\n",
       " 'online',\n",
       " 'unnamed'}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditionalFreq('JJ', horrorDF['POS_sents'], 'zombie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I am interested in seeing if there is any differences between adjectives associated with \"man\" and \"woman\". So, it could be seen from the two cells below. In those 500 sampled horror films, there are more adjectives used to describe males than females. According to those adjectives, man are typically being described as crazy, such as \"defective\", \"mad\", \"sadistic\", \"sick\", \"vicious\", but powerful \"handsome\", \"wealthy\". On the other hand, females are typically associated with beautiful such as \"mysterious\", \"perfect\", \"sexy\", but also negative words such as\"crazy\", \"evil\", \"headstrong\", and \"unsuspecting\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DEFECTIVE',\n",
       " 'Defective',\n",
       " 'depraved',\n",
       " 'distraught',\n",
       " 'free',\n",
       " 'frightened',\n",
       " 'handsome',\n",
       " 'hapless',\n",
       " 'homeless',\n",
       " 'jealous',\n",
       " 'last',\n",
       " 'mad',\n",
       " 'mysterious',\n",
       " 'not-so-young',\n",
       " 'old',\n",
       " 'regular',\n",
       " 'sadistic',\n",
       " 'same',\n",
       " 'sick',\n",
       " 'toothless',\n",
       " 'vicious',\n",
       " 'wanted',\n",
       " 'wealthy',\n",
       " 'young'}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditionalFreq('JJ', horrorDF['POS_sents'], 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'French',\n",
       " 'crazy',\n",
       " 'evil',\n",
       " 'gipsy',\n",
       " 'headstrong',\n",
       " 'mysterious',\n",
       " 'paranoid',\n",
       " 'perfect',\n",
       " 'pregnant',\n",
       " 'sexy',\n",
       " 'unstable',\n",
       " 'unsuspecting',\n",
       " 'year-old',\n",
       " 'young'}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditionalFreq('JJ', horrorDF['POS_sents'], 'woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing the differences between man and woman, I am interested to explore if the gender bias/difference persist among young teenagers -- \"boy\" vs. \"girl\". Due to the size of the sample, there are not many adjectives available. There are several common ones as well, but also there are some distinctive ones. For boys, there are \"ghostly\", \"dark\", and \"rich\" while for girls, there are \"beautiful\", \"opinionated\", \"servant\". Interestingly, we could see that the gender bias persists even among the young generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dark', 'frat', 'ghostly', 'rich', 'strange', 'teenage', 'young'}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditionalFreq('JJ', horrorDF['POS_sents'], 'boy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beautiful',\n",
       " 'little',\n",
       " 'old',\n",
       " 'opinionated',\n",
       " 'regular',\n",
       " 'religious',\n",
       " 'servant',\n",
       " 'teenage',\n",
       " 'young'}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditionalFreq('JJ', horrorDF['POS_sents'], 'girl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am interested in seeing if there is any differences between adverbs associated with specific verbs such as \"run\" and \"find\". It is very interesting to observe that \"run\" is associated with \"brutally\" and \"find\" is associated with \"soon\", which matches our undertanding of horror movies: always escaping (running) and never find the truth until the last minute or too late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brutally'}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditionalFreq('RB', horrorDF['POS_sents'], 'run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'soon'}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditionalFreq('RB', horrorDF['POS_sents'], 'find')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do these distributions suggest about your corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most interesting finding that I have summarized from my corpus of 500 horror movies is that there is obvious gender bias and differences. Fist, among personal pronouns, \"he\" is more frequently occurred than \"she\", and the same applies to \"him\" and \"her\". This order of frequencies show that in horror movie plots, males are more frequently described than females. \n",
    "\n",
    "In addition, I also assessed if there is any differences in terms of adjectives used to describe males and females. It turns out that regardless of age: \"man\" vs. \"woman\" or \"boy\" vs. \"girl\". Males are always associated with crazy and power while females are more closely associated with appearance and physicality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named-Entity Recognition\n",
    "\n",
    "Named Entity Recognition (NER) is also a classification task, which identifies named objects. Included with Stanford NER are a 4 class model trained on the CoNLL 2003 eng.train, a 7 class model trained on the MUC 6 and MUC 7 training data sets, and a 3 class model trained on both data sets plus some additional data (including ACE 2002 and limited data in-house) on the intersection of those class sets. \n",
    "\n",
    "**3 class**:\tLocation, Person, Organization\n",
    "\n",
    "**4 class**:\tLocation, Person, Organization, Misc\n",
    "\n",
    "**7 class**:\tLocation, Person, Organization, Money, Percent, Date, Time\n",
    "\n",
    "These models each use distributional similarity features, which provide some performance gain at the cost of increasing their size and runtime. Also available are the same models missing those features.\n",
    "\n",
    "(We note that the training data for the 3 class model does not include any material from the CoNLL eng.testa or eng.testb data sets, nor any of the MUC 6 or 7 test or devtest datasets, nor Alan Ritter's Twitter NER data, so all of these would be valid tests of its performance.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we tag our first set of exemplary sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('I', 'O'), ('saw', 'O'), ('the', 'O'), ('elephant', 'O'), ('in', 'O'), ('my', 'O'), ('pajamas', 'O'), ('.', 'O')], [('The', 'O'), ('quick', 'O'), ('brown', 'O'), ('fox', 'O'), ('jumped', 'O'), ('over', 'O'), ('the', 'O'), ('lazy', 'O'), ('dog', 'O'), ('.', 'O')], [('While', 'O'), ('in', 'O'), ('France', 'LOCATION'), (',', 'O'), ('Christine', 'PERSON'), ('Lagarde', 'PERSON'), ('discussed', 'O'), ('short-term', 'O'), ('stimulus', 'O'), ('efforts', 'O'), ('in', 'O'), ('a', 'O'), ('recent', 'O'), ('interview', 'O'), ('with', 'O'), ('the', 'O'), ('Wall', 'ORGANIZATION'), ('Street', 'ORGANIZATION'), ('Journal', 'ORGANIZATION'), ('.', 'O')], [('Trayvon', 'PERSON'), ('Benjamin', 'PERSON'), ('Martin', 'PERSON'), ('was', 'O'), ('an', 'O'), ('African', 'O'), ('American', 'O'), ('from', 'O'), ('Miami', 'LOCATION'), ('Gardens', 'LOCATION'), (',', 'O'), ('Florida', 'LOCATION'), (',', 'O'), ('who', 'O'), (',', 'O'), ('at', 'O'), ('17', 'O'), ('years', 'O'), ('old', 'O'), (',', 'O'), ('was', 'O'), ('fatally', 'O'), ('shot', 'O'), ('by', 'O'), ('George', 'PERSON'), ('Zimmerman', 'PERSON'), (',', 'O'), ('a', 'O'), ('neighborhood', 'O'), ('watch', 'O'), ('volunteer', 'O'), (',', 'O'), ('in', 'O'), ('Sanford', 'LOCATION'), (',', 'O'), ('Florida', 'LOCATION'), ('.', 'O')], [('Buffalo', 'LOCATION'), ('buffalo', 'O'), ('Buffalo', 'ORGANIZATION'), ('buffalo', 'O'), ('buffalo', 'O'), ('buffalo', 'O'), ('Buffalo', 'ORGANIZATION'), ('buffalo', 'O')]]\n"
     ]
    }
   ],
   "source": [
    "classified_sents = stanford.nerTagger.tag_sents(tokenized_text)\n",
    "print(classified_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run NER over our entire corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redditTopScores['classified_sents'] = redditTopScores['sentences'].apply(lambda x: stanford.nerTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    [[(Last, O), (year, O), (,, O), (Help, O), (De...\n",
       "8    [[(First, O), (post, O), (in, O), (quite, O), ...\n",
       "7    [[([, O), (Original, O), (Post, O), (], O), ((...\n",
       "6    [[(I, O), (witnessed, O), (this, O), (astoundi...\n",
       "5    [[(I, O), (work, O), (Helpdesk, ORGANIZATION),...\n",
       "4    [[(This, O), (just, O), (happened, O), (..., O...\n",
       "3    [[(Another, O), (tale, O), (from, O), (the, O)...\n",
       "2    [[([, O), (Part, O), (1, O), (], O), ((, O), (...\n",
       "1    [[(>, O), ($, O), (Me, O), (-, O), (Hello, O),...\n",
       "0    [[(So, O), (my, O), (story, O), (starts, O), (...\n",
       "Name: classified_sents, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores['classified_sents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most common entities (which are, of course, boring):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 401),\n",
       " ('I', 245),\n",
       " ('the', 226),\n",
       " (',', 205),\n",
       " ('to', 197),\n",
       " ('a', 143),\n",
       " ('and', 135),\n",
       " ('>', 106),\n",
       " ('you', 102),\n",
       " ('of', 97)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entityCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if ent in entityCounts:\n",
    "                entityCounts[ent] += 1\n",
    "            else:\n",
    "                entityCounts[ent] = 1\n",
    "sortedEntities = sorted(entityCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedEntities[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or those occurring only twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['month',\n",
       " 'working',\n",
       " 'request',\n",
       " 'absolutely',\n",
       " 'order',\n",
       " 'thinking',\n",
       " 'holiday',\n",
       " 'four',\n",
       " 'visit',\n",
       " '60',\n",
       " 'academic',\n",
       " 'personally',\n",
       " 'insurance',\n",
       " 'There',\n",
       " 'both',\n",
       " 'guide',\n",
       " 'S',\n",
       " 'Of',\n",
       " 'connection',\n",
       " 'shortcut',\n",
       " 'Everything',\n",
       " 'random',\n",
       " 'happiness',\n",
       " 'yelled',\n",
       " 'guy',\n",
       " 'certain',\n",
       " 'case',\n",
       " 'tears',\n",
       " 'glad',\n",
       " 'DeskMugPhonePencil1',\n",
       " 'supervisor',\n",
       " 'Ca',\n",
       " 'pages',\n",
       " 'comments',\n",
       " 'soon',\n",
       " 'older',\n",
       " 'ran',\n",
       " 'lived',\n",
       " 'discover',\n",
       " 'systems',\n",
       " 'slightly',\n",
       " 'types',\n",
       " 'error',\n",
       " 'step',\n",
       " 'calls',\n",
       " 'operate',\n",
       " 'command',\n",
       " 'using',\n",
       " 'spent',\n",
       " 'stopped',\n",
       " 'whom',\n",
       " 'large',\n",
       " 'computering',\n",
       " '*Are',\n",
       " 'mistakes',\n",
       " 'staff',\n",
       " 'XYZ',\n",
       " 'upside',\n",
       " 'earlier',\n",
       " '*Note',\n",
       " 'lunch',\n",
       " 'favor',\n",
       " 'drawer*',\n",
       " 'BING',\n",
       " 'ok',\n",
       " 'course',\n",
       " 'window',\n",
       " 'Fail',\n",
       " 'idea',\n",
       " 'scenario',\n",
       " 'completely',\n",
       " 'box',\n",
       " 'potential',\n",
       " '5',\n",
       " 'making',\n",
       " 'heard',\n",
       " 'videos',\n",
       " 'generate',\n",
       " 'first',\n",
       " '17',\n",
       " 'cry',\n",
       " 'allowed',\n",
       " 'gildings',\n",
       " 'shaking',\n",
       " 'While',\n",
       " 'information',\n",
       " '100',\n",
       " 'building',\n",
       " 'live',\n",
       " 'ago',\n",
       " 'check',\n",
       " 'return',\n",
       " 'search',\n",
       " 'SO',\n",
       " 'login',\n",
       " 'me*',\n",
       " 'passed',\n",
       " '#',\n",
       " 'fix',\n",
       " 'flaws',\n",
       " 'business',\n",
       " 'risks',\n",
       " 'Sure',\n",
       " 'DVD',\n",
       " 'themselves',\n",
       " 'Whatever',\n",
       " 'opened',\n",
       " 'share',\n",
       " '=',\n",
       " 'living',\n",
       " 'service',\n",
       " 'took',\n",
       " 'anyway',\n",
       " 'sharing',\n",
       " 'Turns',\n",
       " 'sound',\n",
       " 'often',\n",
       " 'times',\n",
       " 'store',\n",
       " 'party',\n",
       " 'immediately',\n",
       " 'echo',\n",
       " 'whose',\n",
       " 'however',\n",
       " 'above',\n",
       " 'died',\n",
       " 'proud',\n",
       " 'Then',\n",
       " 'yourself',\n",
       " 'suggested',\n",
       " 'meant',\n",
       " 'looking',\n",
       " 'occasionally',\n",
       " 'brave',\n",
       " 'gods',\n",
       " 'try',\n",
       " 'busy',\n",
       " 'same',\n",
       " 'person',\n",
       " 'meet',\n",
       " 'local',\n",
       " 'okay',\n",
       " 'couple',\n",
       " 'loved',\n",
       " 'Computer',\n",
       " 'P',\n",
       " 'brought',\n",
       " 'played',\n",
       " '*I',\n",
       " 'THE',\n",
       " 'site',\n",
       " 'um',\n",
       " 'since',\n",
       " 'door',\n",
       " 'week',\n",
       " 'LOWERCASE',\n",
       " 'pay',\n",
       " 'closed',\n",
       " 'food',\n",
       " 'needed',\n",
       " 'stuff',\n",
       " 'THIS',\n",
       " 'done',\n",
       " 'others',\n",
       " 'real',\n",
       " 'learn',\n",
       " 'avoid',\n",
       " 'used',\n",
       " 'three',\n",
       " 'select',\n",
       " 'properly',\n",
       " 'bane',\n",
       " 'ask',\n",
       " 'helped',\n",
       " 'One',\n",
       " 'Original',\n",
       " 'Thursday',\n",
       " 'future',\n",
       " 'well',\n",
       " 'User',\n",
       " 'stand',\n",
       " 'asset',\n",
       " 'Everyone',\n",
       " 'believe',\n",
       " 'wrong',\n",
       " 'response',\n",
       " 'mouse',\n",
       " 'generic',\n",
       " 'Wow',\n",
       " 'understand',\n",
       " 'yes',\n",
       " 'Give',\n",
       " 'Here',\n",
       " 'year',\n",
       " 'drowned',\n",
       " 'existence',\n",
       " 'sometimes',\n",
       " 'cancer',\n",
       " 'ALL',\n",
       " 'turn',\n",
       " 'mind',\n",
       " 'reply',\n",
       " 'bad',\n",
       " 'pointed',\n",
       " 'way',\n",
       " 'Things',\n",
       " 'its',\n",
       " 'hit',\n",
       " 'difference',\n",
       " 'taking',\n",
       " 'hear',\n",
       " 'In',\n",
       " 'situation',\n",
       " 'blinked',\n",
       " 'received',\n",
       " 'expire',\n",
       " 'ready',\n",
       " 'myself',\n",
       " 'different',\n",
       " 'point',\n",
       " \"'P4ssword\",\n",
       " 'mother',\n",
       " 'avalanche',\n",
       " 'watched',\n",
       " 'Thanks',\n",
       " 'web',\n",
       " 'nice',\n",
       " 'anymore',\n",
       " 'organization',\n",
       " 'HR',\n",
       " 'Steve',\n",
       " 'retail',\n",
       " 'Windows',\n",
       " 'key',\n",
       " 'family',\n",
       " 'nothing',\n",
       " 'speak',\n",
       " 'revealing',\n",
       " 'small',\n",
       " 'nasty',\n",
       " 'Desk',\n",
       " '*type',\n",
       " 'seconds',\n",
       " 'forwarded',\n",
       " 'issues',\n",
       " 'stupid',\n",
       " 'pretty',\n",
       " 'mailboxes',\n",
       " 'stronger',\n",
       " 'moment',\n",
       " 'mess',\n",
       " 'weeks',\n",
       " 'CEO',\n",
       " 'bitter',\n",
       " 'nose',\n",
       " 'willing',\n",
       " 'plugged',\n",
       " 'arms',\n",
       " 'name',\n",
       " 'terrible',\n",
       " 'enjoy']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in sortedEntities if x[1] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also list the most common \"non-objects\". (We note that we're not graphing these because there are so few here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jack', 17),\n",
       " ('Google', 6),\n",
       " ('Smith', 5),\n",
       " ('Steve', 2),\n",
       " ('Reddit', 1),\n",
       " ('Boss', 1),\n",
       " ('Clickity', 1),\n",
       " ('GOOGLE', 1),\n",
       " ('CMD', 1),\n",
       " ('Nono', 1)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonObjCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind == 'O':\n",
    "                continue\n",
    "            elif ent in nonObjCounts:\n",
    "                nonObjCounts[ent] += 1\n",
    "            else:\n",
    "                nonObjCounts[ent] = 1\n",
    "sortedNonObj = sorted(nonObjCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedNonObj[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the Organizations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Google', 6), ('Helpdesk', 1), ('Citrix', 1), ('GOOGLE', 1), ('CMD', 1)]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrgCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != 'ORGANIZATION':\n",
    "                continue\n",
    "            elif ent in OrgCounts:\n",
    "                OrgCounts[ent] += 1\n",
    "            else:\n",
    "                OrgCounts[ent] = 1\n",
    "sortedOrgs = sorted(OrgCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedOrgs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These, of course, have much smaller counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 2*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform NER on a (modest) subset of your corpus of interest. List all of the different kinds of entities tagged? What does their distribution suggest about the focus of your corpus? For a subset of your corpus, tally at least one type of named entity and calculate the Precision, Recall and F-score for the NER classification just performed (using your own hand-codings as \"ground truth\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Named-Entity Recognition (NER) on my corpus of 100 sampled horror film plots so as to identify named objects  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "horrorDF = horrorDF.sample(100)\n",
    "horrorDF['classified_sents'] = horrorDF['sentences'].apply(lambda x: stanford.nerTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241    [[('The, O), (Method, O), (', O), (is, O), (a,...\n",
       "71     [[(Maine, LOCATION), (coastal, O), (town, O), ...\n",
       "180    [[(It, O), ('s, O), (not, O), (uncommon, O), (...\n",
       "130    [[(On, O), (the, O), (night, O), (of, O), (a, ...\n",
       "233    [[(Dracula, O), ('s, O), (Daughter, O), (vs, O...\n",
       "297    [[('Perfection, O), (', O), (is, O), (a, O), (...\n",
       "239    [[(In, O), (Pierce, LOCATION), (County, LOCATI...\n",
       "490    [[(The, O), (Violas, O), ((, O), (an, O), (all...\n",
       "167    [[(Inspired, O), (by, O), (true, O), (accounts...\n",
       "17     [[(A, O), (bloody, O), (,, O), (and, O), (grue...\n",
       "Name: classified_sents, dtype: object"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horrorDF['classified_sents'].iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all of the different kinds of entities tagged?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOCATION', 'O', 'ORGANIZATION', 'PERSON'}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kinds = set()\n",
    "for entry in horrorDF['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            kinds.add(kind)\n",
    "kinds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does their distribution suggest about the focus of your corpus? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the distributions of each category of tag, a function called 'tagDistribution' is composed to facilitate pattern recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tagDistribution(df, tagName, topNum):\n",
    "    Counts = {}\n",
    "    for entry in df['classified_sents']:\n",
    "        for sentence in entry:\n",
    "            for ent, kind in sentence:\n",
    "                if kind != tagName:\n",
    "                    continue\n",
    "                elif ent in Counts:\n",
    "                    Counts[ent] += 1\n",
    "                else:\n",
    "                    Counts[ent] = 1\n",
    "    sortedCounts = sorted(Counts.items(), key = lambda x: x[1], reverse = True)\n",
    "    return sortedCounts[:topNum]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the distribution of Location category of tag: it could be seen that almost of all places of the location cateogries is in the U.S. and among which California seems to be the most \"scary\" place. It is interesting to see that California top the list and could an interesting research question to ask why California to be the place to be mentioned the most of the times in those sampled horror films?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('California', 4),\n",
       " ('America', 3),\n",
       " ('New', 3),\n",
       " ('Earth', 3),\n",
       " ('Iowa', 2),\n",
       " ('Spring', 2),\n",
       " ('Chicago', 2),\n",
       " ('Ohio', 2),\n",
       " ('Hills', 2),\n",
       " ('Texas', 2),\n",
       " ('Grove', 2),\n",
       " ('County', 2),\n",
       " ('Nowell', 1),\n",
       " ('Apartments', 1),\n",
       " ('Detroit', 1),\n",
       " ('Odenbrook', 1),\n",
       " ('Seattle', 1),\n",
       " ('Hopman', 1),\n",
       " ('Florida', 1),\n",
       " ('Bryn', 1)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagDistribution(horrorDF, 'LOCATION', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the distribution of 'O' category of tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 488),\n",
       " (',', 461),\n",
       " ('.', 437),\n",
       " ('a', 320),\n",
       " ('and', 280),\n",
       " ('to', 271),\n",
       " ('of', 246),\n",
       " ('is', 145),\n",
       " ('in', 144),\n",
       " ('his', 100),\n",
       " (\"'s\", 77),\n",
       " ('her', 75),\n",
       " ('with', 71),\n",
       " ('their', 66),\n",
       " ('an', 63),\n",
       " ('that', 61),\n",
       " ('for', 61),\n",
       " ('who', 59),\n",
       " ('on', 57),\n",
       " ('he', 56)]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagDistribution(horrorDF, 'O', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the distribution of organization category of tag and we could see that \"FBI\" is the most frequently occurred organization followed by \"Church\", \"Club\", and \"Catholic\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FBI', 4),\n",
       " ('&', 2),\n",
       " ('Church', 2),\n",
       " ('Insane', 1),\n",
       " ('Club', 1),\n",
       " ('Institute', 1),\n",
       " ('Catholic', 1),\n",
       " ('Samantha', 1),\n",
       " ('Hall', 1),\n",
       " ('the', 1),\n",
       " ('of', 1),\n",
       " ('Death', 1),\n",
       " ('Rubin', 1),\n",
       " ('Farm', 1),\n",
       " ('Russell', 1),\n",
       " ('SCA', 1),\n",
       " ('Birthday', 1),\n",
       " ('Angela', 1),\n",
       " ('Stanton', 1),\n",
       " ('Usher', 1)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagDistribution(horrorDF, 'ORGANIZATION', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the distribution of person category of tag, we could see that the frequency of males names is more than the frequency of female names in genenral. Also, the number of male names is more than the number of female names. Thus, this finding confirmed our previous finding somehow that males is kind having a predominant role in horror films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John', 12),\n",
       " ('Paul', 7),\n",
       " ('Angie', 6),\n",
       " ('Claire', 6),\n",
       " ('Welles', 5),\n",
       " ('Sam', 5),\n",
       " ('Jessica', 5),\n",
       " ('Simon', 5),\n",
       " ('Evelyn', 4),\n",
       " ('Fahey', 4),\n",
       " ('Braxton', 4),\n",
       " ('Madelyn', 4),\n",
       " ('Harry', 4),\n",
       " ('Brad', 4),\n",
       " ('Hoffman', 4),\n",
       " ('Ben', 4),\n",
       " ('Megan', 4),\n",
       " ('Toby', 4),\n",
       " ('William', 4),\n",
       " ('Dustin', 3)]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagDistribution(horrorDF, 'PERSON', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For a subset of your corpus, tally at least one type of named entity and calculate the Precision, Recall and F-score for the NER classification just performed (using your own hand-codings as \"ground truth\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a subset of the first five plots and store the automated tag of entities into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blood</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>;</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gore</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>?</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Are</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>you</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>into</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ent kind\n",
       "0     Do    O\n",
       "1    you    O\n",
       "2   like    O\n",
       "3  blood    O\n",
       "4      ;    O\n",
       "5   gore    O\n",
       "6      ?    O\n",
       "7    Are    O\n",
       "8    you    O\n",
       "9   into    O"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoDF = pandas.DataFrame()\n",
    "for entry in horrorDF['classified_sents'][-5:]:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            autoDF = autoDF.append([(ent, kind)], ignore_index = True)\n",
    "autoDF = autoDF.rename(columns={0: \"ent\", 1: \"kind\"})\n",
    "autoDF.to_csv('../data/auto.csv', index = False)\n",
    "autoDF[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in hand-codings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blood</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>;</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gore</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>?</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Are</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>you</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>into</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cutting</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ent hand\n",
       "0        Do    O\n",
       "1       you    O\n",
       "2      like    O\n",
       "3     blood    O\n",
       "4         ;    O\n",
       "5      gore    O\n",
       "6         ?    O\n",
       "7       Are    O\n",
       "8       you    O\n",
       "9      into    O\n",
       "10  cutting    O"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handDF = pandas.read_csv('../data/hand.csv', usecols = [0,2])\n",
    "handDF.loc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Precision, Recall and F-score for the NER classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCATION:\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F-1 measure: 0.5\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('LOCATION:')\n",
    "print('Precision:', sklearn.metrics.precision_score(handDF['hand'], autoDF['kind'] ,labels = ['LOCATION'], average = 'micro')) #precision\n",
    "print('Recall:', sklearn.metrics.recall_score(autoDF['kind'], handDF['hand'], labels = ['LOCATION'], average = 'micro')) #recall\n",
    "print('F-1 measure:', sklearn.metrics.f1_score(autoDF['kind'], handDF['hand'], labels = ['LOCATION'], average = 'micro')) #F-1 measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON:\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F-1 measure: 0.625\n"
     ]
    }
   ],
   "source": [
    "print('PERSON:')\n",
    "print('Precision:', sklearn.metrics.precision_score(handDF['hand'], autoDF['kind'], labels = ['PERSON'], average = 'micro')) #precision\n",
    "print('Recall:', sklearn.metrics.recall_score(autoDF['kind'], handDF['hand'], labels = ['PERSON'], average = 'micro')) #recall\n",
    "print('F-1 measure:', sklearn.metrics.f1_score(autoDF['kind'], handDF['hand'], labels = ['PERSON'], average = 'micro')) #F-1 measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing\n",
    "\n",
    "Here we will introduce the Stanford Parser by feeding it tokenized text from our initial example sentences. The parser is a dependency parser, but this initial program outputs a simple, self-explanatory phrase-structure representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('ROOT', [Tree('S', [Tree('NP', [Tree('NNP', ['Trayvon']), Tree('NNP', ['Benjamin']), Tree('NNP', ['Martin'])]), Tree('VP', [Tree('VBD', ['was']), Tree('NP', [Tree('NP', [Tree('DT', ['an']), Tree('NNP', ['African']), Tree('NNP', ['American'])]), Tree('PP', [Tree('IN', ['from']), Tree('NP', [Tree('NP', [Tree('NNP', ['Miami']), Tree('NNPS', ['Gardens'])]), Tree(',', [',']), Tree('NP', [Tree('NNP', ['Florida'])]), Tree(',', [',']), Tree('SBAR', [Tree('WHNP', [Tree('WP', ['who'])]), Tree('S', [Tree(',', [',']), Tree('PP', [Tree('IN', ['at']), Tree('ADJP', [Tree('NP', [Tree('CD', ['17']), Tree('NNS', ['years'])]), Tree('JJ', ['old'])])]), Tree(',', [',']), Tree('VP', [Tree('VBD', ['was']), Tree('ADVP', [Tree('RB', ['fatally'])]), Tree('VP', [Tree('VBN', ['shot']), Tree('PP', [Tree('IN', ['by']), Tree('NP', [Tree('NP', [Tree('NNP', ['George']), Tree('NNP', ['Zimmerman'])]), Tree(',', [',']), Tree('NP', [Tree('DT', ['a']), Tree('NN', ['neighborhood']), Tree('NN', ['watch']), Tree('NN', ['volunteer'])]), Tree(',', [','])])]), Tree('PP', [Tree('IN', ['in']), Tree('NP', [Tree('NNP', ['Sanford']), Tree(',', [',']), Tree('NNP', ['Florida'])])])])])])])])])])]), Tree('.', ['.'])])])]\n"
     ]
    }
   ],
   "source": [
    "parses = list(stanford.parser.parse_sents(tokenized_text)) #Converting the iterator to a list so we can call by index. They are still \n",
    "fourthSentParseTree = list(parses[3]) #iterators so be careful about re-running code, without re-running this block\n",
    "print(fourthSentParseTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees are a common data structure and there are a large number of things to do with them. What we are intetered in is the relationship between different types of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def treeRelation(parsetree, relationType, *targets):\n",
    "    if isinstance(parsetree, list):\n",
    "        parsetree = parsetree[0]\n",
    "    if set(targets) & set(parsetree.leaves()) != set(targets):\n",
    "        return []\n",
    "    else:\n",
    "        retList = []\n",
    "        for subT in parsetree.subtrees():\n",
    "            if subT.label() == relationType:\n",
    "                if set(targets) & set(subT.leaves()) == set(targets):\n",
    "                    retList.append([(subT.label(), ' '.join(subT.leaves()))])\n",
    "    return retList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def treeSubRelation(parsetree, relationTypeScope, relationTypeTarget, *targets):\n",
    "    if isinstance(parsetree, list):\n",
    "        parsetree = parsetree[0]\n",
    "    if set(targets) & set(parsetree.leaves()) != set(targets):\n",
    "        return []\n",
    "    else:\n",
    "        retSet = set()\n",
    "        for subT in parsetree.subtrees():\n",
    "            if set(targets) & set(subT.leaves()) == set(targets):\n",
    "                if subT.label() == relationTypeScope:\n",
    "                    for subsub in subT.subtrees():\n",
    "                        if subsub.label()==relationTypeTarget:\n",
    "                            retSet.add(' '.join(subsub.leaves()))\n",
    "    return retSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('NP',\n",
       "   'an African American from Miami Gardens , Florida , who , at 17 years old , was fatally shot by George Zimmerman , a neighborhood watch volunteer , in Sanford , Florida')],\n",
       " [('NP',\n",
       "   'Miami Gardens , Florida , who , at 17 years old , was fatally shot by George Zimmerman , a neighborhood watch volunteer , in Sanford , Florida')]]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeRelation(fourthSentParseTree, 'NP', 'Florida', 'who')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that Florida occurs twice in two different nested noun phrases in the sentence. \n",
    "\n",
    "We can also find all of the verbs within the noun phrase defined by one or more target words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shot'}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeSubRelation(fourthSentParseTree, 'NP', 'VBN', 'Florida', 'who')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we want to to look at the whole tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                   ROOT                                                                                                                       \n",
      "                                                                                                                    |                                                                                                                          \n",
      "                                                                                                                    S                                                                                                                         \n",
      "            ________________________________________________________________________________________________________|_______________________________________________________________________________________________________________________   \n",
      "           |                       VP                                                                                                                                                                                                       | \n",
      "           |              _________|______________                                                                                                                                                                                          |  \n",
      "           |             |                        NP                                                                                                                                                                                        | \n",
      "           |             |          ______________|________________                                                                                                                                                                         |  \n",
      "           |             |         |                               PP                                                                                                                                                                       | \n",
      "           |             |         |               ________________|___________                                                                                                                                                             |  \n",
      "           |             |         |              |                            NP                                                                                                                                                           | \n",
      "           |             |         |              |           _________________|____________________________________                                                                                                                        |  \n",
      "           |             |         |              |          |           |     |     |                             SBAR                                                                                                                     | \n",
      "           |             |         |              |          |           |     |     |    __________________________|______________________________                                                                                         |  \n",
      "           |             |         |              |          |           |     |     |   |                                                         S                                                                                        | \n",
      "           |             |         |              |          |           |     |     |   |     ____________________________________________________|_______________________                                                                 |  \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |                                                 VP                                                               | \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |    _____________________________________________|_______                                                         |  \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |   |     |                                               VP                                                       | \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |   |     |      _________________________________________|________________________________________                |  \n",
      "           |             |         |              |          |           |     |     |   |    |           PP             |   |     |     |                      PP                                                          |               | \n",
      "           |             |         |              |          |           |     |     |   |    |    _______|____          |   |     |     |     _________________|__________                                                 |               |  \n",
      "           |             |         |              |          |           |     |     |   |    |   |           ADJP       |   |     |     |    |                            NP                                               PP              | \n",
      "           |             |         |              |          |           |     |     |   |    |   |        ____|____     |   |     |     |    |           _________________|________________________________     ___________|___            |  \n",
      "           NP            |         NP             |          NP          |     NP    |  WHNP  |   |       NP        |    |   |    ADVP   |    |          NP            |           NP                       |   |               NP          | \n",
      "    _______|_______      |    _____|_______       |      ____|_____      |     |     |   |    |   |    ___|____     |    |   |     |     |    |     _____|______       |    _______|_________________       |   |      _________|_____      |  \n",
      "  NNP     NNP     NNP   VBD  DT   NNP     NNP     IN   NNP        NNPS   ,    NNP    ,   WP   ,   IN  CD      NNS   JJ   ,  VBD    RB   VBN   IN  NNP          NNP     ,   DT      NN        NN      NN     ,   IN   NNP        ,    NNP    . \n",
      "   |       |       |     |   |     |       |      |     |          |     |     |     |   |    |   |   |        |    |    |   |     |     |    |    |            |      |   |       |         |       |      |   |     |         |     |     |  \n",
      "Trayvon Benjamin Martin was  an African American from Miami     Gardens  ,  Florida  ,  who   ,   at  17     years old   ,  was fatally shot  by George     Zimmerman  ,   a  neighborhood watch volunteer  ,   in Sanford      ,  Florida  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fourthSentParseTree[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or another sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ROOT                           \n",
      "                      |                              \n",
      "                      S                             \n",
      "       _______________|___________________________   \n",
      "      |                          VP               | \n",
      "      |                __________|___             |  \n",
      "      |               |              PP           | \n",
      "      |               |      ________|___         |  \n",
      "      NP              |     |            NP       | \n",
      "  ____|__________     |     |     _______|____    |  \n",
      " DT   JJ    JJ   NN  VBD    IN   DT      JJ   NN  . \n",
      " |    |     |    |    |     |    |       |    |   |  \n",
      "The quick brown fox jumped over the     lazy dog  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "list(parses[1])[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency parsing and graph representations\n",
    "\n",
    "Dependency parsing was developed to robustly capture linguistic dependencies from text. The complex tags associated with these parses are detailed [here]('http://universaldependencies.org/u/overview/syntax.html'). When parsing with the dependency parser, we will work directly from the untokenized text. Note that no *processing* takes place before parsing sentences--we do not remove so-called stop words or anything that plays a syntactic role in the sentence, although anaphora resolution and related normalization may be performed before or after parsing to enhance the value of information extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I saw the elephant in my pajamas.',\n",
       " 'The quick brown fox jumped over the lazy dog.',\n",
       " 'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.',\n",
       " 'Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.',\n",
       " 'Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo']"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x11da32d90>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'root': [5]}),\n",
      "                 'feats': None,\n",
      "                 'head': None,\n",
      "                 'lemma': None,\n",
      "                 'rel': None,\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'The'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'amod',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'quick'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'amod',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'brown'},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'amod': [2, 3],\n",
      "                                      'det': [1]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 5,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'nsubj',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'fox'},\n",
      "             5: {'address': 5,\n",
      "                 'ctag': 'VBD',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'nmod': [9],\n",
      "                                      'nsubj': [4]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 0,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'root',\n",
      "                 'tag': 'VBD',\n",
      "                 'word': 'jumped'},\n",
      "             6: {'address': 6,\n",
      "                 'ctag': 'IN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 9,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'case',\n",
      "                 'tag': 'IN',\n",
      "                 'word': 'over'},\n",
      "             7: {'address': 7,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 9,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             8: {'address': 8,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 9,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'amod',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'lazy'},\n",
      "             9: {'address': 9,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'amod': [8],\n",
      "                                      'case': [6],\n",
      "                                      'det': [7]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 5,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'nmod',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'dog'}})\n"
     ]
    }
   ],
   "source": [
    "depParses = list(stanford.depParser.raw_parse_sents(text)) #Converting the iterator to a list so we can call by index. They are still \n",
    "secondSentDepParseTree = list(depParses[1])[0] #iterators so be careful about re-running code, without re-running this block\n",
    "print(secondSentDepParseTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a graph and we can convert it to a dot file and use that to visulize it. Try traversing the tree and extracting elements that are nearby one another. We note that unless you have the graphviz successfully installed on your computer (which is not necessary to complete this homework), the following graphviz call will trigger an error. If you are interested in installing graphviz and working on a Mac, consider installing through [homebrew](https://brew.sh), a package manager (i.e., with the command \"brew install graphviz\", once brew is installed). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"467pt\" height=\"302pt\"\n",
       " viewBox=\"0.00 0.00 467.37 302.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 298)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-298 463.3657,-298 463.3657,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"193.7949\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"193.7949\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5 (jumped)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M193.7949,-257.7616C193.7949,-246.3597 193.7949,-231.4342 193.7949,-218.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"197.295,-218.2121 193.7949,-208.2121 190.295,-218.2121 197.295,-218.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"205.0708\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"152.7949\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4 (fox)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M184.9506,-171.6975C182.2192,-166.0286 179.2067,-159.7594 176.457,-154 172.9867,-146.731 169.2503,-138.8578 165.7948,-131.5568\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"168.7462,-129.6107 161.3081,-122.0658 162.4177,-132.6024 168.7462,-129.6107\"/>\n",
       "<text text-anchor=\"middle\" x=\"191.9639\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"316.7949\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">9 (dog)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;9 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M219.5798,-171.9716C237.9481,-159.1286 262.8214,-141.7376 282.8098,-127.7619\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"284.8541,-130.6033 291.044,-122.0047 280.843,-124.8665 284.8541,-130.6033\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.7397\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"28.7949\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 (The)</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"108.7949\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2 (quick)</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"195.7949\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3 (brown)</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>4&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M126.8005,-85.9716C108.2827,-73.1286 83.2073,-55.7376 63.0563,-41.7619\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"64.967,-38.8277 54.7552,-36.0047 60.9777,-44.5797 64.967,-38.8277\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.3467\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.4637,-85.7616C137.4551,-74.0176 129.534,-58.5355 122.7802,-45.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"125.7834,-43.5204 118.1127,-36.2121 119.5517,-46.7088 125.7834,-43.5204\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.3467\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>4&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M161.9141,-85.7616C167.7861,-74.0176 175.5272,-58.5355 182.1275,-45.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"185.3472,-46.7216 186.6889,-36.2121 179.0862,-43.5911 185.3472,-46.7216\"/>\n",
       "<text text-anchor=\"middle\" x=\"193.3467\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"279.7949\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6 (over)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>9&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M308.9482,-85.7616C303.9446,-74.1316 297.3638,-58.8357 291.721,-45.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"294.7976,-44.0148 287.6304,-36.2121 288.3674,-46.7813 294.7976,-44.0148\"/>\n",
       "<text text-anchor=\"middle\" x=\"312.8398\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"354.7949\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">7 (the)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;7 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>9&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M324.8537,-85.7616C329.9926,-74.1316 336.7512,-58.8357 342.5466,-45.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"345.9074,-46.7736 346.7477,-36.2121 339.5046,-43.9444 345.9074,-46.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"347.3467\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"429.7949\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">8 (lazy)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>9&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M340.4834,-85.9716C357.2078,-73.2433 379.8019,-56.0478 398.0799,-42.1371\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"400.2997,-44.8461 406.1376,-36.0047 396.0604,-39.2758 400.2997,-44.8461\"/>\n",
       "<text text-anchor=\"middle\" x=\"396.3467\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x11da2dbe0>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    secondSentGraph = graphviz.Source(secondSentDepParseTree.to_dot())\n",
    "except:\n",
    "    secondSentGraph = None\n",
    "    print(\"There was a problem with graphviz, likely your missing the program, https://www.graphviz.org/download/\")\n",
    "secondSentGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or another sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"902pt\" height=\"560pt\"\n",
       " viewBox=\"0.00 0.00 901.96 560.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 556)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-556 897.9575,-556 897.9575,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"232.3833\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"232.3833\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">7 (American)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;7 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M232.3833,-515.7616C232.3833,-504.3597 232.3833,-489.4342 232.3833,-476.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"235.8834,-476.2121 232.3833,-466.2121 228.8834,-476.2121 235.8834,-476.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"243.6592\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"74.3833\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3 (Martin)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;3 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>7&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M192.5259,-429.8504C180.9641,-424.3453 168.399,-418.1273 157.0454,-412 141.9107,-403.8322 125.6384,-394.1858 111.5678,-385.5556\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"113.0198,-382.3384 102.6735,-380.0569 109.3388,-388.2925 113.0198,-382.3384\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.5522\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"158.3833\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4 (was)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;4 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>7&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M216.6898,-429.7616C206.1921,-417.5615 192.2231,-401.3273 180.5899,-387.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"183.2297,-385.5094 174.0542,-380.2121 177.9236,-390.0751 183.2297,-385.5094\"/>\n",
       "<text text-anchor=\"middle\" x=\"210.4902\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cop</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"232.3833\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5 (an)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;5 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>7&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M232.3833,-429.7616C232.3833,-418.3597 232.3833,-403.4342 232.3833,-390.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"235.8834,-390.2121 232.3833,-380.2121 228.8834,-390.2121 235.8834,-390.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"240.9351\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"316.3833\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6 (African)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;6 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>7&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M250.1975,-429.7616C262.2253,-417.4475 278.2673,-401.0235 291.5454,-387.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"294.1111,-389.8115 298.5947,-380.2121 289.1035,-384.9203 294.1111,-389.8115\"/>\n",
       "<text text-anchor=\"middle\" x=\"309.9351\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"418.3833\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">10 (Gardens)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;10 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M278.035,-436.267C298.523,-430.2297 322.6866,-422.0184 343.3833,-412 358.1468,-404.8536 373.3934,-395.1776 386.2526,-386.2414\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"388.6132,-388.8578 394.7385,-380.213 384.5592,-383.1511 388.6132,-388.8578\"/>\n",
       "<text text-anchor=\"middle\" x=\"383.3281\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"41.3833\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 (Trayvon)</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"146.3833\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2 (Benjamin)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>3&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M67.3848,-343.7616C62.9222,-332.1316 57.0528,-316.8357 52.02,-303.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"55.2219,-302.2945 48.3717,-294.2121 48.6866,-304.8023 55.2219,-302.2945\"/>\n",
       "<text text-anchor=\"middle\" x=\"89.9351\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>3&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M104.1951,-343.8208C111.0895,-338.6633 117.9793,-332.6262 123.3833,-326 128.7334,-319.4399 133.135,-311.4322 136.6039,-303.7643\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"139.9028,-304.9461 140.5002,-294.3681 133.4367,-302.2648 139.9028,-304.9461\"/>\n",
       "<text text-anchor=\"middle\" x=\"162.9351\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"280.3833\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">8 (from)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>10&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M373.3287,-344.0907C361.8967,-338.8521 349.8661,-332.7092 339.2935,-326 327.8536,-318.7405 316.2709,-309.4264 306.4387,-300.809\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"308.7445,-298.1755 298.9649,-294.0999 304.0683,-303.3846 308.7445,-298.1755\"/>\n",
       "<text text-anchor=\"middle\" x=\"351.4282\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"366.3833\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">9 (Miami)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;9 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>10&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M386.9119,-343.7718C380.7813,-338.7844 375.0843,-332.8348 371.2798,-326 367.6468,-319.4733 365.8966,-311.7178 365.176,-304.286\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"368.6673,-304.0028 364.7539,-294.1572 361.6734,-304.2943 368.6673,-304.0028\"/>\n",
       "<text text-anchor=\"middle\" x=\"400.9351\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>23</title>\n",
       "<text text-anchor=\"middle\" x=\"454.3833\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">23 (shot)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;23 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M426.018,-343.7616C430.8863,-332.1316 437.2893,-316.8357 442.7796,-303.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"446.1267,-304.788 446.7596,-294.2121 439.6696,-302.085 446.1267,-304.788\"/>\n",
       "<text text-anchor=\"middle\" x=\"461.9214\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"547.3833\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">12 (Florida)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>10&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M457.4282,-343.9087C467.763,-338.5897 478.7248,-332.4531 488.3833,-326 499.4601,-318.5993 510.8133,-309.4245 520.5648,-300.9626\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"523.1734,-303.3276 528.3381,-294.0768 518.5319,-298.0877 523.1734,-303.3276\"/>\n",
       "<text text-anchor=\"middle\" x=\"523.7144\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">appos</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"246.3833\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">14 (who)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;14 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>23&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M421.1702,-260.9437C418.2294,-259.8618 415.2725,-258.8603 412.3833,-258 368.0759,-244.8067 352.1421,-258.8621 309.9351,-240 296.1147,-233.8237 282.6618,-223.9798 271.7188,-214.6536\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"274.0307,-212.0258 264.2247,-208.014 269.3886,-217.2652 274.0307,-212.0258\"/>\n",
       "<text text-anchor=\"middle\" x=\"337.6074\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubjpass</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>19</title>\n",
       "<text text-anchor=\"middle\" x=\"328.3833\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">19 (old)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;19 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>23&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M421.1784,-260.4383C409.7229,-254.5703 397.0234,-247.4896 386.0659,-240 375.2101,-232.5799 364.1045,-223.4008 354.5734,-214.9408\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"356.738,-212.1792 346.9776,-208.058 352.0377,-217.3664 356.738,-212.1792\"/>\n",
       "<text text-anchor=\"middle\" x=\"401.542\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advcl</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>21</title>\n",
       "<text text-anchor=\"middle\" x=\"409.3833\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">21 (was)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;21 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>23&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M438.0881,-257.7967C433.7634,-252.3398 429.379,-246.1607 426.0591,-240 422.3584,-233.1328 419.2732,-225.2945 416.8039,-217.8935\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"420.108,-216.7304 413.8185,-208.2044 413.4184,-218.7917 420.108,-216.7304\"/>\n",
       "<text text-anchor=\"middle\" x=\"448.5454\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">auxpass</text>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>22</title>\n",
       "<text text-anchor=\"middle\" x=\"499.3833\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">22 (fatally)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;22 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>23&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M463.9266,-257.7616C470.0718,-246.0176 478.1729,-230.5355 485.0802,-217.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"488.3186,-218.6951 489.8537,-208.2121 482.1163,-215.4497 488.3186,-218.6951\"/>\n",
       "<text text-anchor=\"middle\" x=\"502.9351\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advmod</text>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>26</title>\n",
       "<text text-anchor=\"middle\" x=\"612.3833\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">26 (Zimmerman)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;26 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>23&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M487.5792,-260.8936C500.7359,-254.6924 515.9102,-247.2707 529.3833,-240 544.7081,-231.7301 561.2104,-221.973 575.4323,-213.2835\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"577.2801,-216.2561 583.9618,-208.0339 573.611,-210.2947 577.2801,-216.2561\"/>\n",
       "<text text-anchor=\"middle\" x=\"569.3281\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 36 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>36</title>\n",
       "<text text-anchor=\"middle\" x=\"761.3833\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">36 (Florida)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;36 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>23&#45;&gt;36</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M487.6128,-260.9978C490.55,-259.9042 493.5016,-258.8852 496.3833,-258 536.6277,-245.6374 548.4602,-249.8864 589.3833,-240 630.2385,-230.13 675.8976,-216.7448 709.9,-206.3074\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"711.0902,-209.603 719.6127,-203.3088 709.0252,-202.9145 711.0902,-209.603\"/>\n",
       "<text text-anchor=\"middle\" x=\"658.3281\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>16</title>\n",
       "<text text-anchor=\"middle\" x=\"296.3833\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">16 (at)</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"377.3833\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">17 (17)</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>18</title>\n",
       "<text text-anchor=\"middle\" x=\"377.3833\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">18 (years)</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;17 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>18&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M377.3833,-85.7616C377.3833,-74.3597 377.3833,-59.4342 377.3833,-46.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"380.8834,-46.2121 377.3833,-36.2121 373.8834,-46.2121 380.8834,-46.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"402.2729\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nummod</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;16 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>19&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M321.5969,-171.7616C317.2695,-160.1316 311.578,-144.8357 306.6977,-131.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"309.9276,-130.3637 303.1599,-122.2121 303.367,-132.8049 309.9276,-130.3637\"/>\n",
       "<text text-anchor=\"middle\" x=\"326.4282\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;18 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>19&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M338.7749,-171.7616C345.5313,-159.9036 354.459,-144.2345 362.0275,-130.951\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"365.0971,-132.6334 367.0066,-122.2121 359.0151,-129.1681 365.0971,-132.6334\"/>\n",
       "<text text-anchor=\"middle\" x=\"393.7178\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod:npmod</text>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>24</title>\n",
       "<text text-anchor=\"middle\" x=\"472.3833\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">24 (by)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;24 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>26&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M573.1869,-171.9496C562.328,-166.5419 550.6763,-160.3501 540.2935,-154 527.6297,-146.2549 514.3446,-136.8017 502.9168,-128.2084\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"505.0333,-125.4208 494.9593,-122.1398 500.7884,-130.9869 505.0333,-125.4208\"/>\n",
       "<text text-anchor=\"middle\" x=\"552.4282\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>25</title>\n",
       "<text text-anchor=\"middle\" x=\"560.3833\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">25 (George)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;25 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>26&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M589.2392,-171.951C583.6851,-166.6739 578.2261,-160.5473 574.2798,-154 570.2509,-147.3157 567.3575,-139.4301 565.2923,-131.9215\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"568.6687,-130.9902 562.9608,-122.0643 561.8567,-132.6015 568.6687,-130.9902\"/>\n",
       "<text text-anchor=\"middle\" x=\"603.9351\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 31 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>31</title>\n",
       "<text text-anchor=\"middle\" x=\"668.3833\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">31 (volunteer)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;31 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>26&#45;&gt;31</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M624.2595,-171.7616C631.981,-159.9036 642.1841,-144.2345 650.8338,-130.951\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"654.0005,-132.502 656.5243,-122.2121 648.1345,-128.6822 654.0005,-132.502\"/>\n",
       "<text text-anchor=\"middle\" x=\"660.7144\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">appos</text>\n",
       "</g>\n",
       "<!-- 33 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>33</title>\n",
       "<text text-anchor=\"middle\" x=\"761.3833\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">33 (in)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;33 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>36&#45;&gt;33</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M761.3833,-171.7616C761.3833,-160.3597 761.3833,-145.4342 761.3833,-132.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"764.8834,-132.2121 761.3833,-122.2121 757.8834,-132.2121 764.8834,-132.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"773.4282\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 34 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>34</title>\n",
       "<text text-anchor=\"middle\" x=\"850.3833\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">34 (Sanford)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;34 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>36&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M780.2579,-171.7616C793.0016,-159.4475 809.9985,-143.0235 824.067,-129.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"826.7767,-131.6779 831.5359,-122.2121 821.9125,-126.644 826.7767,-131.6779\"/>\n",
       "<text text-anchor=\"middle\" x=\"840.9351\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>28</title>\n",
       "<text text-anchor=\"middle\" x=\"563.3833\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">28 (a)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;28 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>31&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M646.3719,-85.9716C630.9715,-73.358 610.2148,-56.3573 593.313,-42.5139\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"595.3198,-39.6334 585.3658,-36.0047 590.8843,-45.0488 595.3198,-39.6334\"/>\n",
       "<text text-anchor=\"middle\" x=\"630.9351\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>29</title>\n",
       "<text text-anchor=\"middle\" x=\"668.3833\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">29 (neighborhood)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;29 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>31&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M668.3833,-85.7616C668.3833,-74.3597 668.3833,-59.4342 668.3833,-46.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"671.8834,-46.2121 668.3833,-36.2121 664.8834,-46.2121 671.8834,-46.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"697.9351\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>30</title>\n",
       "<text text-anchor=\"middle\" x=\"784.3833\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">30 (watch)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;30 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>31&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M703.3154,-85.9914C712.713,-80.629 722.6789,-74.4499 731.3833,-68 741.2881,-60.6606 751.3323,-51.6634 759.9744,-43.3341\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"762.5027,-45.7565 767.1694,-36.2448 757.5896,-40.7703 762.5027,-45.7565\"/>\n",
       "<text text-anchor=\"middle\" x=\"778.9351\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x11da63f98>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    graph = graphviz.Source(list(depParses[3])[0].to_dot())\n",
    "except IndexError:\n",
    "    print(\"You likely have to rerun the depParses\")\n",
    "    raise\n",
    "except:\n",
    "    graph = None\n",
    "    print(\"There was a problem with graphviz, likely your missing the program, https://www.graphviz.org/download/\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do a dependency parse on the reddit sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topPostDepParse = list(stanford.depParser.parse_sents(redditTopScores['sentences'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a few seconds, but now lets look at the parse tree from one of the processed sentences.\n",
    "\n",
    "The sentence is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So anyway , I get a call from an older gentleman who 's quite bitter and mean right off the bat ( does n't like that I asked for his address / telephone number to verify the account , hates that he has to speak with a machine before reaching an agent , etc . ) .\n"
     ]
    }
   ],
   "source": [
    "targetSentence = 7\n",
    "print(' '.join(redditTopScores['sentences'][0][targetSentence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which leads to a very rich dependancy tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"937pt\" height=\"818pt\"\n",
       " viewBox=\"0.00 0.00 936.76 818.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 814)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-814 932.7622,-814 932.7622,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"197.2432\" y=\"-787.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"197.2432\" y=\"-701.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5 (get)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M197.2432,-773.7616C197.2432,-762.3597 197.2432,-747.4342 197.2432,-734.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"200.7433,-734.2121 197.2432,-724.2121 193.7433,-734.2121 200.7433,-734.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"208.519\" y=\"-744.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"27.2432\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 (So)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;1 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M170.0991,-700.0143C147.3043,-694.3052 114.3518,-684.4249 88.1396,-670 75.8462,-663.2347 63.6272,-653.8632 53.3969,-645.0603\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"55.4559,-642.2079 45.6552,-638.1831 50.8069,-647.4412 55.4559,-642.2079\"/>\n",
       "<text text-anchor=\"middle\" x=\"110.7949\" y=\"-658.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advmod</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"112.2432\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2 (anyway)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;2 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M170.0131,-688.3776C162.5318,-682.9299 154.6844,-676.6103 148.1396,-670 141.1828,-662.9735 134.5653,-654.4941 128.9508,-646.5301\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"131.7966,-644.4907 123.2834,-638.1838 126.0055,-648.423 131.7966,-644.4907\"/>\n",
       "<text text-anchor=\"middle\" x=\"170.7949\" y=\"-658.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advmod</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"197.2432\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4 (I)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M197.2432,-687.7616C197.2432,-676.3597 197.2432,-661.4342 197.2432,-648.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"200.7433,-648.2121 197.2432,-638.2121 193.7433,-648.2121 200.7433,-648.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"212.4121\" y=\"-658.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 34 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>34</title>\n",
       "<text text-anchor=\"middle\" x=\"285.2432\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">34 (number)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;34 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M215.9057,-687.7616C228.5062,-675.4475 245.3121,-659.0235 259.2225,-645.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"261.9019,-647.7046 266.6075,-638.2121 257.0094,-642.6983 261.9019,-647.7046\"/>\n",
       "<text text-anchor=\"middle\" x=\"257.3501\" y=\"-658.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dep</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"436.2432\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">7 (call)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M224.6595,-696.1347C267.4462,-680.7387 350.1953,-650.9628 398.5577,-633.5604\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"399.815,-636.8278 408.0394,-630.1486 397.4449,-630.2412 399.815,-636.8278\"/>\n",
       "<text text-anchor=\"middle\" x=\"343.688\" y=\"-658.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>25</title>\n",
       "<text text-anchor=\"middle\" x=\"134.2432\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">25 (like)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;25 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>34&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M253.5886,-601.9716C230.6361,-588.8993 199.4103,-571.115 174.6559,-557.0165\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"176.2777,-553.9124 165.856,-552.0047 172.8134,-559.9951 176.2777,-553.9124\"/>\n",
       "<text text-anchor=\"middle\" x=\"229.3501\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dep</text>\n",
       "</g>\n",
       "<!-- 33 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>33</title>\n",
       "<text text-anchor=\"middle\" x=\"243.2432\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">33 (telephone)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;33 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>34&#45;&gt;33</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M268.1992,-601.9999C263.7507,-596.5462 259.3183,-590.3179 256.1396,-584 252.7439,-577.2506 250.1862,-569.5259 248.2828,-562.1997\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"251.6492,-561.2197 246.0086,-552.2511 244.8252,-562.7797 251.6492,-561.2197\"/>\n",
       "<text text-anchor=\"middle\" x=\"285.7949\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 36 -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>36</title>\n",
       "<text text-anchor=\"middle\" x=\"348.2432\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">36 (verify)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;36 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>34&#45;&gt;36</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M301.2178,-601.6334C305.8716,-596.0714 310.876,-589.8772 315.2432,-584 320.6828,-576.6796 326.2677,-568.5078 331.2602,-560.9267\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"334.2958,-562.6785 336.8046,-552.385 328.4242,-558.8673 334.2958,-562.6785\"/>\n",
       "<text text-anchor=\"middle\" x=\"333.4019\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">acl</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"436.2432\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6 (a)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>7&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M436.2432,-601.7616C436.2432,-590.3597 436.2432,-575.4342 436.2432,-562.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"439.7433,-562.2121 436.2432,-552.2121 432.7433,-562.2121 439.7433,-562.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"444.7949\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>11</title>\n",
       "<text text-anchor=\"middle\" x=\"550.2432\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">11 (gentleman)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;11 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M460.1413,-601.9716C477.0137,-589.2433 499.8077,-572.0478 518.2475,-558.1371\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"520.5012,-560.8212 526.3765,-552.0047 516.2855,-555.233 520.5012,-560.8212\"/>\n",
       "<text text-anchor=\"middle\" x=\"516.188\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"473.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">8 (from)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>11&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M533.9134,-515.7616C522.9901,-503.5615 508.4548,-487.3273 496.35,-473.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"498.8274,-471.3276 489.5493,-466.2121 493.6123,-475.9969 498.8274,-471.3276\"/>\n",
       "<text text-anchor=\"middle\" x=\"529.2881\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"550.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">9 (an)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;9 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>11&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M550.2432,-515.7616C550.2432,-504.3597 550.2432,-489.4342 550.2432,-476.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"553.7433,-476.2121 550.2432,-466.2121 546.7433,-476.2121 553.7433,-476.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"558.7949\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"631.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">10 (older)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;10 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>11&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M567.4212,-515.7616C578.912,-503.5615 594.2023,-487.3273 606.936,-473.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"609.7814,-475.8913 614.0899,-466.2121 604.6858,-471.0919 609.7814,-475.8913\"/>\n",
       "<text text-anchor=\"middle\" x=\"611.7949\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>15</title>\n",
       "<text text-anchor=\"middle\" x=\"721.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">15 (bitter)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;15 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>11&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M593.0332,-515.8322C605.4626,-510.3267 618.987,-504.113 631.2432,-498 647.9569,-489.6637 666.0209,-479.8025 681.5483,-471.05\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"683.3984,-474.0245 690.3681,-466.0448 679.9435,-467.9365 683.3984,-474.0245\"/>\n",
       "<text text-anchor=\"middle\" x=\"679.7813\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"563.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">12 (who)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;12 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>15&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M684.884,-432.4737C671.4995,-426.4508 656.3352,-419.2608 642.9053,-412 628.0589,-403.9733 612.215,-394.2776 598.5992,-385.5689\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"600.305,-382.504 590.0064,-380.0161 596.5057,-388.3833 600.305,-382.504\"/>\n",
       "<text text-anchor=\"middle\" x=\"658.4121\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>13</title>\n",
       "<text text-anchor=\"middle\" x=\"641.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">13 (&#39;s)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;13 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>15&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M704.2772,-429.7616C692.9283,-417.5615 677.8267,-401.3273 665.2502,-387.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"667.5584,-385.1501 658.1847,-380.2121 662.4331,-389.9179 667.5584,-385.1501\"/>\n",
       "<text text-anchor=\"middle\" x=\"696.3501\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cop</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"721.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">14 (quite)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;14 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>15&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M721.2432,-429.7616C721.2432,-418.3597 721.2432,-403.4342 721.2432,-390.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"724.7433,-390.2121 721.2432,-380.2121 717.7433,-390.2121 724.7433,-390.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"743.7949\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advmod</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"811.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">17 (mean)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;17 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>15&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M748.3991,-429.9089C755.785,-424.5008 763.5789,-418.3189 770.2432,-412 777.861,-404.7769 785.3844,-396.1589 791.8658,-388.1289\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"794.7809,-390.0837 798.2032,-380.0569 789.275,-385.761 794.7809,-390.0837\"/>\n",
       "<text text-anchor=\"middle\" x=\"795.2949\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conj</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>16</title>\n",
       "<text text-anchor=\"middle\" x=\"897.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">16 (and)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;16 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>15&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M757.6789,-434.8179C774.2648,-428.4646 793.9983,-420.4062 811.2432,-412 827.4419,-404.1037 844.723,-394.3378 859.513,-385.5382\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"861.6045,-388.3645 868.368,-380.2093 857.9951,-382.3667 861.6045,-388.3645\"/>\n",
       "<text text-anchor=\"middle\" x=\"844.457\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cc</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>18</title>\n",
       "<text text-anchor=\"middle\" x=\"773.2432\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">18 (right)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;18 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>17&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M792.8839,-343.8974C788.3869,-338.5346 784.0384,-332.3788 781.1396,-326 778.0753,-319.2569 776.1728,-311.5343 774.9993,-304.2081\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"778.4705,-303.7587 773.7805,-294.2585 771.5224,-304.6099 778.4705,-303.7587\"/>\n",
       "<text text-anchor=\"middle\" x=\"803.7949\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advmod</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>21</title>\n",
       "<text text-anchor=\"middle\" x=\"856.2432\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">21 (bat)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;21 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>17&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M820.7865,-343.7616C826.9316,-332.0176 835.0327,-316.5355 841.94,-303.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"845.1784,-304.6951 846.7136,-294.2121 838.9762,-301.4497 845.1784,-304.6951\"/>\n",
       "<text text-anchor=\"middle\" x=\"853.188\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>19</title>\n",
       "<text text-anchor=\"middle\" x=\"817.2432\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">19 (off)</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;19 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>21&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M847.9723,-257.7616C842.6465,-246.0176 835.6255,-230.5355 829.6392,-217.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"832.8198,-215.8739 825.5021,-208.2121 826.4447,-218.7649 832.8198,-215.8739\"/>\n",
       "<text text-anchor=\"middle\" x=\"851.2881\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>20</title>\n",
       "<text text-anchor=\"middle\" x=\"894.2432\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">20 (the)</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;20 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>21&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M864.302,-257.7616C869.4408,-246.1316 876.1995,-230.8357 881.9948,-217.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"885.3557,-218.7736 886.196,-208.2121 878.9529,-215.9444 885.3557,-218.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"886.7949\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>23</title>\n",
       "<text text-anchor=\"middle\" x=\"34.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">23 (does)</text>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>24</title>\n",
       "<text text-anchor=\"middle\" x=\"114.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">24 (n&#39;t)</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;23 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>25&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M113.0357,-515.7616C98.5844,-503.3335 79.2653,-486.719 63.3739,-473.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"65.284,-470.0789 55.42,-466.2121 60.7197,-475.3862 65.284,-470.0789\"/>\n",
       "<text text-anchor=\"middle\" x=\"100.3501\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">aux</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;24 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>25&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M130.0017,-515.7616C127.3235,-504.2456 123.8095,-489.1353 120.7795,-476.1064\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"124.1528,-475.1594 118.4785,-466.2121 117.3347,-476.745 124.1528,-475.1594\"/>\n",
       "<text text-anchor=\"middle\" x=\"136.3501\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">neg</text>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>28</title>\n",
       "<text text-anchor=\"middle\" x=\"197.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">28 (asked)</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;28 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>25&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M147.6038,-515.7616C156.3741,-503.7896 167.9901,-487.9328 177.7802,-474.5685\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"180.8156,-476.3475 183.9017,-466.2121 175.1687,-472.2108 180.8156,-476.3475\"/>\n",
       "<text text-anchor=\"middle\" x=\"188.9019\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ccomp</text>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>26</title>\n",
       "<text text-anchor=\"middle\" x=\"54.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">26 (that)</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;26 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>28&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M160.7847,-429.8674C150.2297,-424.3627 138.7795,-418.1406 128.4775,-412 114.9215,-403.9198 100.4376,-394.3813 87.8957,-385.8132\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"89.7783,-382.86 79.5583,-380.0664 85.8056,-388.6235 89.7783,-382.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"143.626\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>27</title>\n",
       "<text text-anchor=\"middle\" x=\"131.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">27 (I)</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;27 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>28&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M183.2463,-429.7616C173.9709,-417.6756 161.6572,-401.6304 151.3405,-388.1874\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"154.0847,-386.0143 145.2199,-380.2121 148.5315,-390.2761 154.0847,-386.0143\"/>\n",
       "<text text-anchor=\"middle\" x=\"183.4121\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 31 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>31</title>\n",
       "<text text-anchor=\"middle\" x=\"218.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">31 (address)</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;31 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>28&#45;&gt;31</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M201.6967,-429.7616C204.5088,-418.2456 208.1985,-403.1353 211.38,-390.1064\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"214.8239,-390.757 213.796,-380.2121 208.0237,-389.0964 214.8239,-390.757\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.188\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>29</title>\n",
       "<text text-anchor=\"middle\" x=\"178.2432\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">29 (for)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;29 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>31&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M209.7602,-343.7616C204.2979,-332.0176 197.0969,-316.5355 190.9571,-303.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"194.1048,-301.8032 186.7139,-294.2121 187.7577,-304.7554 194.1048,-301.8032\"/>\n",
       "<text text-anchor=\"middle\" x=\"213.2881\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>30</title>\n",
       "<text text-anchor=\"middle\" x=\"255.2432\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">30 (his)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;30 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>31&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M226.0899,-343.7616C231.0935,-332.1316 237.6743,-316.8357 243.3171,-303.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"246.6707,-304.7813 247.4077,-294.2121 240.2405,-302.0148 246.6707,-304.7813\"/>\n",
       "<text text-anchor=\"middle\" x=\"269.5811\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod:poss</text>\n",
       "</g>\n",
       "<!-- 35 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>35</title>\n",
       "<text text-anchor=\"middle\" x=\"292.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">35 (to)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;35 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>36&#45;&gt;35</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M336.367,-515.7616C328.6455,-503.9036 318.4424,-488.2345 309.7927,-474.951\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"312.492,-472.6822 304.1022,-466.2121 306.626,-476.502 312.492,-472.6822\"/>\n",
       "<text text-anchor=\"middle\" x=\"338.626\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 38 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>38</title>\n",
       "<text text-anchor=\"middle\" x=\"380.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">38 (account)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;38 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>36&#45;&gt;38</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M355.0295,-515.7616C359.357,-504.1316 365.0485,-488.8357 369.9287,-475.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"373.2594,-476.8049 373.4666,-466.2121 366.6989,-474.3637 373.2594,-476.8049\"/>\n",
       "<text text-anchor=\"middle\" x=\"378.688\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 37 -->\n",
       "<g id=\"node36\" class=\"node\">\n",
       "<title>37</title>\n",
       "<text text-anchor=\"middle\" x=\"308.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">37 (the)</text>\n",
       "</g>\n",
       "<!-- 38&#45;&gt;37 -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>38&#45;&gt;37</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M364.9738,-429.7616C354.8553,-417.6756 341.4221,-401.6304 330.1675,-388.1874\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"332.5936,-385.6329 323.4905,-380.2121 327.2262,-390.1265 332.5936,-385.6329\"/>\n",
       "<text text-anchor=\"middle\" x=\"357.7949\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 40 -->\n",
       "<g id=\"node37\" class=\"node\">\n",
       "<title>40</title>\n",
       "<text text-anchor=\"middle\" x=\"392.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">40 (hates)</text>\n",
       "</g>\n",
       "<!-- 38&#45;&gt;40 -->\n",
       "<g id=\"edge36\" class=\"edge\">\n",
       "<title>38&#45;&gt;40</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M382.7881,-429.7616C384.379,-418.3597 386.4617,-403.4342 388.2673,-390.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"391.7863,-390.5999 389.7019,-380.2121 384.8535,-389.6324 391.7863,-390.5999\"/>\n",
       "<text text-anchor=\"middle\" x=\"399.2949\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conj</text>\n",
       "</g>\n",
       "<!-- 54 -->\n",
       "<g id=\"node38\" class=\"node\">\n",
       "<title>54</title>\n",
       "<text text-anchor=\"middle\" x=\"475.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">54 (etc)</text>\n",
       "</g>\n",
       "<!-- 38&#45;&gt;54 -->\n",
       "<g id=\"edge37\" class=\"edge\">\n",
       "<title>38&#45;&gt;54</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M400.3902,-429.7616C414.119,-417.3335 432.4721,-400.719 447.569,-387.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"450.0605,-389.518 455.1251,-380.2121 445.3627,-384.3286 450.0605,-389.518\"/>\n",
       "<text text-anchor=\"middle\" x=\"446.2949\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conj</text>\n",
       "</g>\n",
       "<!-- 50 -->\n",
       "<g id=\"node39\" class=\"node\">\n",
       "<title>50</title>\n",
       "<text text-anchor=\"middle\" x=\"355.2432\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">50 (reaching)</text>\n",
       "</g>\n",
       "<!-- 40&#45;&gt;50 -->\n",
       "<g id=\"edge38\" class=\"edge\">\n",
       "<title>40&#45;&gt;50</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M381.8654,-343.9548C378.8009,-338.2964 375.564,-331.9684 372.9258,-326 369.8035,-318.9366 366.829,-311.1344 364.2407,-303.8357\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"367.5289,-302.6344 360.9728,-294.3117 360.9078,-304.9063 367.5289,-302.6344\"/>\n",
       "<text text-anchor=\"middle\" x=\"388.4019\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advcl</text>\n",
       "</g>\n",
       "<!-- 43 -->\n",
       "<g id=\"node40\" class=\"node\">\n",
       "<title>43</title>\n",
       "<text text-anchor=\"middle\" x=\"484.2432\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">43 (has)</text>\n",
       "</g>\n",
       "<!-- 40&#45;&gt;43 -->\n",
       "<g id=\"edge39\" class=\"edge\">\n",
       "<title>40&#45;&gt;43</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M411.754,-343.7616C425.0492,-331.3335 442.8228,-314.719 457.4429,-301.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"459.8453,-303.5978 464.7605,-294.2121 455.0651,-298.4841 459.8453,-303.5978\"/>\n",
       "<text text-anchor=\"middle\" x=\"462.9019\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ccomp</text>\n",
       "</g>\n",
       "<!-- 49 -->\n",
       "<g id=\"node48\" class=\"node\">\n",
       "<title>49</title>\n",
       "<text text-anchor=\"middle\" x=\"261.2432\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">49 (before)</text>\n",
       "</g>\n",
       "<!-- 50&#45;&gt;49 -->\n",
       "<g id=\"edge48\" class=\"edge\">\n",
       "<title>50&#45;&gt;49</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M335.3082,-257.7616C321.724,-245.3335 303.564,-228.719 288.626,-215.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"290.89,-212.3799 281.1494,-208.2121 286.1649,-217.5446 290.89,-212.3799\"/>\n",
       "<text text-anchor=\"middle\" x=\"328.626\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 52 -->\n",
       "<g id=\"node49\" class=\"node\">\n",
       "<title>52</title>\n",
       "<text text-anchor=\"middle\" x=\"355.2432\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">52 (agent)</text>\n",
       "</g>\n",
       "<!-- 50&#45;&gt;52 -->\n",
       "<g id=\"edge47\" class=\"edge\">\n",
       "<title>50&#45;&gt;52</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M355.2432,-257.7616C355.2432,-246.3597 355.2432,-231.4342 355.2432,-218.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"358.7433,-218.2121 355.2432,-208.2121 351.7433,-218.2121 358.7433,-218.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"367.688\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 41 -->\n",
       "<g id=\"node41\" class=\"node\">\n",
       "<title>41</title>\n",
       "<text text-anchor=\"middle\" x=\"441.2432\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">41 (that)</text>\n",
       "</g>\n",
       "<!-- 43&#45;&gt;41 -->\n",
       "<g id=\"edge42\" class=\"edge\">\n",
       "<title>43&#45;&gt;41</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M475.124,-257.7616C469.252,-246.0176 461.5109,-230.5355 454.9106,-217.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"457.9519,-215.5911 450.3492,-208.2121 451.6909,-218.7216 457.9519,-215.5911\"/>\n",
       "<text text-anchor=\"middle\" x=\"480.626\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 42 -->\n",
       "<g id=\"node42\" class=\"node\">\n",
       "<title>42</title>\n",
       "<text text-anchor=\"middle\" x=\"519.2432\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">42 (he)</text>\n",
       "</g>\n",
       "<!-- 43&#45;&gt;42 -->\n",
       "<g id=\"edge41\" class=\"edge\">\n",
       "<title>43&#45;&gt;42</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M491.6658,-257.7616C496.3989,-246.1316 502.624,-230.8357 507.9618,-217.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"511.3035,-218.7938 511.8313,-208.2121 504.8198,-216.1551 511.3035,-218.7938\"/>\n",
       "<text text-anchor=\"middle\" x=\"519.4121\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 45 -->\n",
       "<g id=\"node43\" class=\"node\">\n",
       "<title>45</title>\n",
       "<text text-anchor=\"middle\" x=\"602.2432\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">45 (speak)</text>\n",
       "</g>\n",
       "<!-- 43&#45;&gt;45 -->\n",
       "<g id=\"edge40\" class=\"edge\">\n",
       "<title>43&#45;&gt;45</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M512.2659,-257.8955C520.7059,-252.2887 529.9317,-246.0042 538.2432,-240 549.4263,-231.9213 561.41,-222.7141 571.9487,-214.4211\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"574.3826,-216.9582 580.0479,-208.0053 570.036,-211.4712 574.3826,-216.9582\"/>\n",
       "<text text-anchor=\"middle\" x=\"575.2949\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">xcomp</text>\n",
       "</g>\n",
       "<!-- 44 -->\n",
       "<g id=\"node44\" class=\"node\">\n",
       "<title>44</title>\n",
       "<text text-anchor=\"middle\" x=\"566.2432\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">44 (to)</text>\n",
       "</g>\n",
       "<!-- 45&#45;&gt;44 -->\n",
       "<g id=\"edge43\" class=\"edge\">\n",
       "<title>45&#45;&gt;44</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M594.1225,-171.7289C591.6357,-166.0614 588.9142,-159.785 586.4775,-154 583.4286,-146.7615 580.2055,-138.8989 577.2496,-131.5982\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"580.4079,-130.0712 573.4259,-122.1023 573.9145,-132.6859 580.4079,-130.0712\"/>\n",
       "<text text-anchor=\"middle\" x=\"601.626\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 48 -->\n",
       "<g id=\"node45\" class=\"node\">\n",
       "<title>48</title>\n",
       "<text text-anchor=\"middle\" x=\"656.2432\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">48 (machine)</text>\n",
       "</g>\n",
       "<!-- 45&#45;&gt;48 -->\n",
       "<g id=\"edge44\" class=\"edge\">\n",
       "<title>45&#45;&gt;48</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M613.6952,-171.7616C621.1409,-159.9036 630.9796,-144.2345 639.3204,-130.951\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"642.4541,-132.5422 644.8077,-122.2121 636.5258,-128.8198 642.4541,-132.5422\"/>\n",
       "<text text-anchor=\"middle\" x=\"649.188\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 46 -->\n",
       "<g id=\"node46\" class=\"node\">\n",
       "<title>46</title>\n",
       "<text text-anchor=\"middle\" x=\"617.2432\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">46 (with)</text>\n",
       "</g>\n",
       "<!-- 48&#45;&gt;46 -->\n",
       "<g id=\"edge45\" class=\"edge\">\n",
       "<title>48&#45;&gt;46</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M647.9723,-85.7616C642.6465,-74.0176 635.6255,-58.5355 629.6392,-45.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"632.8198,-43.8739 625.5021,-36.2121 626.4447,-46.7649 632.8198,-43.8739\"/>\n",
       "<text text-anchor=\"middle\" x=\"651.2881\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 47 -->\n",
       "<g id=\"node47\" class=\"node\">\n",
       "<title>47</title>\n",
       "<text text-anchor=\"middle\" x=\"696.2432\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">47 (a)</text>\n",
       "</g>\n",
       "<!-- 48&#45;&gt;47 -->\n",
       "<g id=\"edge46\" class=\"edge\">\n",
       "<title>48&#45;&gt;47</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M664.7261,-85.7616C670.1885,-74.0176 677.3895,-58.5355 683.5293,-45.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"686.7286,-46.7554 687.7724,-36.2121 680.3815,-43.8032 686.7286,-46.7554\"/>\n",
       "<text text-anchor=\"middle\" x=\"687.7949\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 51 -->\n",
       "<g id=\"node50\" class=\"node\">\n",
       "<title>51</title>\n",
       "<text text-anchor=\"middle\" x=\"355.2432\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">51 (an)</text>\n",
       "</g>\n",
       "<!-- 52&#45;&gt;51 -->\n",
       "<g id=\"edge49\" class=\"edge\">\n",
       "<title>52&#45;&gt;51</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M355.2432,-171.7616C355.2432,-160.3597 355.2432,-145.4342 355.2432,-132.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"358.7433,-132.2121 355.2432,-122.2121 351.7433,-132.2121 358.7433,-132.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"363.7949\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x11db2ba20>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    graph = graphviz.Source(list(topPostDepParse[targetSentence])[0].to_dot())\n",
    "except IndexError:\n",
    "    print(\"You likely have to rerun the depParses\")\n",
    "    raise\n",
    "except:\n",
    "    graph = None\n",
    "    print(\"There was a problem with graphviz, likely your missing the program, https://www.graphviz.org/download/\")\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 3*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, parse a (modest) subset of your corpus of interest. How deep are the phrase structure and dependency parse trees nested? How does parse depth relate to perceived sentence complexity? What are five things you can extract from these parses for subsequent analysis? (e.g., nouns collocated in a noun phrase; adjectives that modify a noun; etc.) Capture these sets of things for a focal set of words (e.g., \"Bush\", \"Obama\", \"Trump\"). What do they reveal about the roles that these entities are perceived to play in the social world inscribed by your texts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse a (modest) subset of your corpus of interest. How deep are the phrase structure and dependency parse trees nested? How does parse depth relate to perceived sentence complexity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I randomly chose to parse the eleventh plot summary in my horror film corpus. The complete plot summary is presented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When a gamer rolls seven critical failures in a row, this unknown to anyone, is an invocation that summons a minor demon from hell who is now free to roam the convention in an attempt to earn her horns by tempting people into sin. She has to get 10 points, and during a conversation with a fellow demon on her hell phone gets her first point by telling a mother her baby is ugly and causing her to hate it. A man in a bar finds the iPhone prototype and rather than return it, the demon suggests in his ear that he could make a lot of money by selling it to Gizmodo. She angers Guest of Honor Peter S. Beagle by telling him that his panel has been replaced by \"Twilight\" filking. She stands behind a SCA braggart with a sign saying, \"Liar.\" An attempt to get a nerdy fan to pick up a girl by slapping her on the ass goes wrong when the girl likes it and they begin kissing passionately. The demon loses points and cannot believe it. Trying to encourage a goth girl to kill herself fails as well and even a lawyer talking on the phone mocks her as an amateur. Tempting a woman on a diet to go ahead and gorge herself results in a point though. She encourages a boy to throw away a banana peel and litter which then causes a hapless man to slip and fall all the way down the escalators. The demon sings a truly diabolical song in the filk room, and even though she is off-key and the song points out what hypocrites they all are for applauding, they do so anyway. She tells a woman to check out her room and when she does she discovers her husband has been having an affair and it breaks her heart. Sitting despondently, the woman is surprised to see Doctor Who actor David Tennant standing in front of her asking her out on a date. It is love at first sight and the demon loses nearly all her accumulated points. She shouts out, \"Curse you, true love. And TV\\'s David Tennant!\" A fan confronts the demon, having realized what she is up to. The demon tries to deny it, then bribe her with winning lottery numbers (which turn out to be only the numbers from \"Lost\" which she recognizes). The fan then tweets the entire convention to be on the lookout for the demon and not succumb to her tricks. Ruined and with hardly any points, the demon slowly walks out of the convention. With only minutes left of her time on Earth, our hapless demon is locked in despair, sure she will never earn her horns. Until, however..'"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horrorDF['plot'].iloc[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "horror10Parse = list(stanford.depParser.parse_sents(horrorDF['sentences'].iloc[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the plot summary sentence by sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When a gamer rolls seven critical failures in a row , this unknown to anyone , is an invocation that summons a minor demon from hell who is now free to roam the convention in an attempt to earn her horns by tempting people into sin .\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(horrorDF['sentences'].iloc[10][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing initiation and take a look at the dependency tree: a 10-layer tree that is constructed from the sentence given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"1337pt\" height=\"818pt\"\n",
       " viewBox=\"0.00 0.00 1336.93 818.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 814)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-814 1332.9277,-814 1332.9277,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"397.626\" y=\"-787.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>19</title>\n",
       "<text text-anchor=\"middle\" x=\"397.626\" y=\"-701.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">19 (invocation)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;19 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M397.626,-773.7616C397.626,-762.3597 397.626,-747.4342 397.626,-734.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"401.1261,-734.2121 397.626,-724.2121 394.1261,-734.2121 401.1261,-734.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"408.9019\" y=\"-744.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"167.626\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4 (rolls)</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;4 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>19&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M349.4104,-687.9716C307.2727,-672.2157 246.8281,-649.6147 207.4012,-634.8725\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"208.4467,-631.5268 197.8542,-631.3027 205.995,-638.0834 208.4467,-631.5268\"/>\n",
       "<text text-anchor=\"middle\" x=\"311.7847\" y=\"-658.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advcl</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<text text-anchor=\"middle\" x=\"305.626\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">13 (unknown)</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;13 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>19&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M376.3839,-687.9339C369.8681,-682.2747 362.7268,-675.9514 356.3086,-670 347.8428,-662.15 338.8075,-653.372 330.7453,-645.3882\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"333.2138,-642.9069 323.6591,-638.3289 328.2734,-647.8661 333.2138,-642.9069\"/>\n",
       "<text text-anchor=\"middle\" x=\"375.2847\" y=\"-658.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ccomp</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"397.626\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">17 (is)</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;17 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>19&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M397.626,-687.7616C397.626,-676.3597 397.626,-661.4342 397.626,-648.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"401.1261,-648.2121 397.626,-638.2121 394.1261,-648.2121 401.1261,-648.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"407.7329\" y=\"-658.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cop</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>18</title>\n",
       "<text text-anchor=\"middle\" x=\"470.626\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">18 (an)</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;18 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>19&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M413.1074,-687.7616C423.3665,-675.6756 436.9862,-659.6304 448.3972,-646.1874\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"451.3638,-648.1009 455.1669,-638.2121 446.0272,-643.5709 451.3638,-648.1009\"/>\n",
       "<text text-anchor=\"middle\" x=\"447.1777\" y=\"-658.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>21</title>\n",
       "<text text-anchor=\"middle\" x=\"571.626\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">21 (summons)</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;21 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>19&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M434.1021,-687.9716C460.8986,-674.7273 497.4813,-656.6462 526.1797,-642.462\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"527.7839,-645.5733 535.1979,-638.0047 524.6823,-639.2979 527.7839,-645.5733\"/>\n",
       "<text text-anchor=\"middle\" x=\"518.1641\" y=\"-658.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"34.626\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 (When)</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"53.626\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2 (a)</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"122.626\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3 (gamer)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>3&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M107.7977,-515.7041C103.2135,-510.0356 98.1526,-503.7648 93.5225,-498 87.292,-490.2426 80.5359,-481.7909 74.3852,-474.0809\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"76.9726,-471.7117 68.0022,-466.0739 71.499,-476.0751 76.9726,-471.7117\"/>\n",
       "<text text-anchor=\"middle\" x=\"102.1777\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;1 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M137.1248,-607.2822C123.3673,-601.0226 107.1787,-592.9092 93.5225,-584 82.3766,-576.7285 71.0234,-567.5829 61.2978,-559.108\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"63.3452,-556.2443 53.5515,-552.2028 58.6873,-561.4697 63.3452,-556.2443\"/>\n",
       "<text text-anchor=\"middle\" x=\"116.1777\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advmod</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>4&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M158.0826,-601.7616C151.9375,-590.0176 143.8364,-574.5355 136.9291,-561.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"139.893,-559.4497 132.1556,-552.2121 133.6907,-562.6951 139.893,-559.4497\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.7949\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"214.626\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">7 (failures)</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;7 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M177.5935,-601.7616C184.0117,-590.0176 192.4729,-574.5355 199.6871,-561.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"202.9484,-562.6657 204.6729,-552.2121 196.8059,-559.3087 202.9484,-562.6657\"/>\n",
       "<text text-anchor=\"middle\" x=\"207.0708\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"132.626\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5 (seven)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;5 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>7&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M185.7538,-515.8905C178.4872,-510.6139 171.0093,-504.5027 164.8467,-498 158.3436,-491.1381 152.3712,-482.7898 147.3815,-474.8958\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"150.3486,-473.0384 142.1896,-466.2795 144.3529,-476.6512 150.3486,-473.0384\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.5156\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nummod</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"221.626\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6 (critical)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>7&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M216.1105,-515.7616C217.0386,-504.3597 218.2534,-489.4342 219.3067,-476.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"222.8207,-476.4631 220.1436,-466.2121 215.8438,-475.8952 222.8207,-476.4631\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.1777\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"309.626\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">10 (row)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;10 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M234.773,-515.7616C248.5018,-503.3335 266.8549,-486.719 281.9518,-473.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"284.4434,-475.518 289.508,-466.2121 279.7455,-470.3286 284.4434,-475.518\"/>\n",
       "<text text-anchor=\"middle\" x=\"284.5708\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"273.626\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">8 (in)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>10&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M301.9913,-429.7616C297.1229,-418.1316 290.72,-402.8357 285.2297,-389.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"288.3396,-388.085 281.2496,-380.2121 281.8825,-390.788 288.3396,-388.085\"/>\n",
       "<text text-anchor=\"middle\" x=\"306.6709\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"345.626\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">9 (a)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;9 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>10&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M317.2607,-429.7616C322.129,-418.1316 328.5319,-402.8357 334.0223,-389.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"337.3694,-390.788 338.0023,-380.2121 330.9123,-388.085 337.3694,-390.788\"/>\n",
       "<text text-anchor=\"middle\" x=\"339.1777\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"302.626\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">12 (this)</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;12 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>13&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M304.9898,-601.7616C304.592,-590.3597 304.0714,-575.4342 303.62,-562.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"307.1079,-562.084 303.2613,-552.2121 300.1121,-562.3281 307.1079,-562.084\"/>\n",
       "<text text-anchor=\"middle\" x=\"314.7329\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dep</text>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>15</title>\n",
       "<text text-anchor=\"middle\" x=\"393.626\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">15 (anyone)</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;15 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>13&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M324.2885,-601.7616C336.889,-589.4475 353.6949,-573.0235 367.6053,-559.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"370.2847,-561.7046 374.9903,-552.2121 365.3922,-556.6983 370.2847,-561.7046\"/>\n",
       "<text text-anchor=\"middle\" x=\"371.5708\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"393.626\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">14 (to)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;14 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>15&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M393.626,-515.7616C393.626,-504.3597 393.626,-489.4342 393.626,-476.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"397.1261,-476.2121 393.626,-466.2121 390.1261,-476.2121 397.1261,-476.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"405.6709\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>20</title>\n",
       "<text text-anchor=\"middle\" x=\"485.626\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">20 (that)</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>21&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M553.3876,-601.7616C541.0735,-589.4475 524.6495,-573.0235 511.0553,-559.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"513.3841,-556.8083 503.8381,-552.2121 508.4343,-561.7581 513.3841,-556.8083\"/>\n",
       "<text text-anchor=\"middle\" x=\"549.7949\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>24</title>\n",
       "<text text-anchor=\"middle\" x=\"575.626\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">24 (demon)</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;24 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>21&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M572.4743,-601.7616C573.0046,-590.3597 573.6988,-575.4342 574.3007,-562.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"577.8104,-562.3639 574.7789,-552.2121 570.818,-562.0387 577.8104,-562.3639\"/>\n",
       "<text text-anchor=\"middle\" x=\"587.0708\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>26</title>\n",
       "<text text-anchor=\"middle\" x=\"666.626\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">26 (hell)</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;26 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>21&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M591.773,-601.7616C605.5018,-589.3335 623.8549,-572.719 638.9518,-559.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"641.4434,-561.518 646.508,-552.2121 636.7455,-556.3286 641.4434,-561.518\"/>\n",
       "<text text-anchor=\"middle\" x=\"641.5708\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>22</title>\n",
       "<text text-anchor=\"middle\" x=\"492.626\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">22 (a)</text>\n",
       "</g>\n",
       "<!-- 24&#45;&gt;22 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>24&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M558.0238,-515.7616C546.1393,-503.4475 530.2882,-487.0235 517.1682,-473.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"519.6657,-470.977 510.2028,-466.2121 514.6288,-475.8382 519.6657,-470.977\"/>\n",
       "<text text-anchor=\"middle\" x=\"548.1777\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>23</title>\n",
       "<text text-anchor=\"middle\" x=\"575.626\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">23 (minor)</text>\n",
       "</g>\n",
       "<!-- 24&#45;&gt;23 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>24&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M575.626,-515.7616C575.626,-504.3597 575.626,-489.4342 575.626,-476.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"579.1261,-476.2121 575.626,-466.2121 572.1261,-476.2121 579.1261,-476.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"591.1777\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>25</title>\n",
       "<text text-anchor=\"middle\" x=\"666.626\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">25 (from)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;25 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>26&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M666.626,-515.7616C666.626,-504.3597 666.626,-489.4342 666.626,-476.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"670.1261,-476.2121 666.626,-466.2121 663.1261,-476.2121 670.1261,-476.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"678.6709\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>30</title>\n",
       "<text text-anchor=\"middle\" x=\"751.626\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">30 (free)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;30 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>26&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M684.6523,-515.7616C696.8232,-503.4475 713.0562,-487.0235 726.4924,-473.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"729.0853,-475.7848 733.6256,-466.2121 724.1067,-470.8641 729.0853,-475.7848\"/>\n",
       "<text text-anchor=\"middle\" x=\"737.1641\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>27</title>\n",
       "<text text-anchor=\"middle\" x=\"634.626\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">27 (who)</text>\n",
       "</g>\n",
       "<!-- 30&#45;&gt;27 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>30&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M722.5188,-429.8756C713.9445,-424.3205 704.6288,-418.0692 696.2881,-412 685.3841,-404.0656 673.8077,-394.8924 663.6656,-386.5864\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"665.8175,-383.8242 655.8797,-380.1512 661.358,-389.2198 665.8175,-383.8242\"/>\n",
       "<text text-anchor=\"middle\" x=\"711.7949\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>28</title>\n",
       "<text text-anchor=\"middle\" x=\"712.626\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">28 (is)</text>\n",
       "</g>\n",
       "<!-- 30&#45;&gt;28 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>30&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M743.3551,-429.7616C738.0293,-418.0176 731.0083,-402.5355 725.022,-389.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"728.2026,-387.8739 720.885,-380.2121 721.8275,-390.7649 728.2026,-387.8739\"/>\n",
       "<text text-anchor=\"middle\" x=\"744.7329\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cop</text>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>29</title>\n",
       "<text text-anchor=\"middle\" x=\"790.626\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">29 (now)</text>\n",
       "</g>\n",
       "<!-- 30&#45;&gt;29 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>30&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M759.8969,-429.7616C765.2226,-418.0176 772.2436,-402.5355 778.2299,-389.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"781.4244,-390.7649 782.367,-380.2121 775.0493,-387.8739 781.4244,-390.7649\"/>\n",
       "<text text-anchor=\"middle\" x=\"796.1777\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advmod</text>\n",
       "</g>\n",
       "<!-- 32 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>32</title>\n",
       "<text text-anchor=\"middle\" x=\"877.626\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">32 (roam)</text>\n",
       "</g>\n",
       "<!-- 30&#45;&gt;32 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>30&#45;&gt;32</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M783.7653,-433.9688C796.3187,-427.9157 810.5645,-420.3145 822.626,-412 832.9801,-404.8624 843.4214,-395.9133 852.383,-387.5663\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"855.0235,-389.8843 859.8381,-380.4466 850.1889,-384.822 855.0235,-389.8843\"/>\n",
       "<text text-anchor=\"middle\" x=\"859.6777\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">xcomp</text>\n",
       "</g>\n",
       "<!-- 31 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>31</title>\n",
       "<text text-anchor=\"middle\" x=\"779.626\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">31 (to)</text>\n",
       "</g>\n",
       "<!-- 32&#45;&gt;31 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>32&#45;&gt;31</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M856.8427,-343.7616C842.6804,-331.3335 823.7477,-314.719 808.174,-301.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"810.2042,-298.1773 800.3793,-294.2121 805.587,-303.4387 810.2042,-298.1773\"/>\n",
       "<text text-anchor=\"middle\" x=\"849.0088\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 34 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>34</title>\n",
       "<text text-anchor=\"middle\" x=\"877.626\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">34 (convention)</text>\n",
       "</g>\n",
       "<!-- 32&#45;&gt;34 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>32&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M877.626,-343.7616C877.626,-332.3597 877.626,-317.4342 877.626,-304.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"881.1261,-304.2121 877.626,-294.2121 874.1261,-304.2121 881.1261,-304.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"890.0708\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 37 -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>37</title>\n",
       "<text text-anchor=\"middle\" x=\"1007.626\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">37 (attempt)</text>\n",
       "</g>\n",
       "<!-- 32&#45;&gt;37 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>32&#45;&gt;37</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M904.8782,-343.9716C924.3786,-331.0713 950.8156,-313.5822 971.9894,-299.575\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"974.0005,-302.4412 980.4096,-294.0047 970.1383,-296.603 974.0005,-302.4412\"/>\n",
       "<text text-anchor=\"middle\" x=\"966.5708\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 33 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>33</title>\n",
       "<text text-anchor=\"middle\" x=\"868.626\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">33 (the)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;33 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>34&#45;&gt;33</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M875.7173,-257.7616C874.5241,-246.3597 872.9621,-231.4342 871.6079,-218.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"875.0538,-217.7935 870.5319,-208.2121 868.0918,-218.5221 875.0538,-217.7935\"/>\n",
       "<text text-anchor=\"middle\" x=\"883.1777\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 35 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>35</title>\n",
       "<text text-anchor=\"middle\" x=\"943.626\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">35 (in)</text>\n",
       "</g>\n",
       "<!-- 37&#45;&gt;35 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>37&#45;&gt;35</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M994.0532,-257.7616C985.1438,-245.7896 973.3434,-229.9328 963.3979,-216.5685\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"965.9571,-214.1449 957.1792,-208.2121 960.3415,-218.324 965.9571,-214.1449\"/>\n",
       "<text text-anchor=\"middle\" x=\"991.6709\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 36 -->\n",
       "<g id=\"node36\" class=\"node\">\n",
       "<title>36</title>\n",
       "<text text-anchor=\"middle\" x=\"1016.626\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">36 (an)</text>\n",
       "</g>\n",
       "<!-- 37&#45;&gt;36 -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>37&#45;&gt;36</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1009.5346,-257.7616C1010.7279,-246.3597 1012.2898,-231.4342 1013.644,-218.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1017.1601,-218.5221 1014.7201,-208.2121 1010.1982,-217.7935 1017.1601,-218.5221\"/>\n",
       "<text text-anchor=\"middle\" x=\"1022.1777\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 39 -->\n",
       "<g id=\"node37\" class=\"node\">\n",
       "<title>39</title>\n",
       "<text text-anchor=\"middle\" x=\"1095.626\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">39 (earn)</text>\n",
       "</g>\n",
       "<!-- 37&#45;&gt;39 -->\n",
       "<g id=\"edge36\" class=\"edge\">\n",
       "<title>37&#45;&gt;39</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1026.2885,-257.7616C1038.889,-245.4475 1055.6949,-229.0235 1069.6053,-215.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1072.2847,-217.7046 1076.9903,-208.2121 1067.3922,-212.6983 1072.2847,-217.7046\"/>\n",
       "<text text-anchor=\"middle\" x=\"1065.7847\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">acl</text>\n",
       "</g>\n",
       "<!-- 38 -->\n",
       "<g id=\"node38\" class=\"node\">\n",
       "<title>38</title>\n",
       "<text text-anchor=\"middle\" x=\"966.626\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">38 (to)</text>\n",
       "</g>\n",
       "<!-- 39&#45;&gt;38 -->\n",
       "<g id=\"edge38\" class=\"edge\">\n",
       "<title>39&#45;&gt;38</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1065.1768,-171.8959C1055.9936,-166.2891 1045.9427,-160.0045 1036.8604,-154 1024.4019,-145.7635 1010.9852,-136.3516 999.25,-127.9319\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1001.1972,-125.0209 991.0399,-122.0074 997.101,-130.6973 1001.1972,-125.0209\"/>\n",
       "<text text-anchor=\"middle\" x=\"1052.0088\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 41 -->\n",
       "<g id=\"node39\" class=\"node\">\n",
       "<title>41</title>\n",
       "<text text-anchor=\"middle\" x=\"1048.626\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">41 (horns)</text>\n",
       "</g>\n",
       "<!-- 39&#45;&gt;41 -->\n",
       "<g id=\"edge37\" class=\"edge\">\n",
       "<title>39&#45;&gt;41</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1085.6585,-171.7616C1079.2403,-160.0176 1070.7791,-144.5355 1063.5648,-131.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1066.4461,-129.3087 1058.5791,-122.2121 1060.3035,-132.6657 1066.4461,-129.3087\"/>\n",
       "<text text-anchor=\"middle\" x=\"1088.0708\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 44 -->\n",
       "<g id=\"node40\" class=\"node\">\n",
       "<title>44</title>\n",
       "<text text-anchor=\"middle\" x=\"1143.626\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">44 (people)</text>\n",
       "</g>\n",
       "<!-- 39&#45;&gt;44 -->\n",
       "<g id=\"edge39\" class=\"edge\">\n",
       "<title>39&#45;&gt;44</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1105.8055,-171.7616C1112.424,-159.9036 1121.1695,-144.2345 1128.5835,-130.951\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1131.6436,-132.6499 1133.4611,-122.2121 1125.5312,-129.2383 1131.6436,-132.6499\"/>\n",
       "<text text-anchor=\"middle\" x=\"1138.5708\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 46 -->\n",
       "<g id=\"node41\" class=\"node\">\n",
       "<title>46</title>\n",
       "<text text-anchor=\"middle\" x=\"1274.626\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">46 (sin)</text>\n",
       "</g>\n",
       "<!-- 39&#45;&gt;46 -->\n",
       "<g id=\"edge40\" class=\"edge\">\n",
       "<title>39&#45;&gt;46</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1129.2945,-173.8241C1159.4898,-159.3168 1203.8016,-138.0273 1235.5492,-122.7743\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1237.471,-125.7341 1244.9689,-118.2486 1234.4395,-119.4245 1237.471,-125.7341\"/>\n",
       "<text text-anchor=\"middle\" x=\"1212.5708\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 40 -->\n",
       "<g id=\"node42\" class=\"node\">\n",
       "<title>40</title>\n",
       "<text text-anchor=\"middle\" x=\"1026.626\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">40 (her)</text>\n",
       "</g>\n",
       "<!-- 41&#45;&gt;40 -->\n",
       "<g id=\"edge41\" class=\"edge\">\n",
       "<title>41&#45;&gt;40</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1035.8165,-85.7262C1032.6451,-80.2682 1029.6658,-74.1061 1027.9502,-68 1026.0249,-61.1475 1025.1967,-53.5571 1024.9606,-46.4039\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1028.4605,-46.3798 1024.9792,-36.3733 1021.4605,-46.3667 1028.4605,-46.3798\"/>\n",
       "<text text-anchor=\"middle\" x=\"1058.9639\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod:poss</text>\n",
       "</g>\n",
       "<!-- 42 -->\n",
       "<g id=\"node43\" class=\"node\">\n",
       "<title>42</title>\n",
       "<text text-anchor=\"middle\" x=\"1106.626\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">42 (by)</text>\n",
       "</g>\n",
       "<!-- 44&#45;&gt;42 -->\n",
       "<g id=\"edge42\" class=\"edge\">\n",
       "<title>44&#45;&gt;42</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1135.7792,-85.7616C1130.7756,-74.1316 1124.1948,-58.8357 1118.552,-45.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1121.6286,-44.0148 1114.4614,-36.2121 1115.1985,-46.7813 1121.6286,-44.0148\"/>\n",
       "<text text-anchor=\"middle\" x=\"1139.6709\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 43 -->\n",
       "<g id=\"node44\" class=\"node\">\n",
       "<title>43</title>\n",
       "<text text-anchor=\"middle\" x=\"1199.626\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">43 (tempting)</text>\n",
       "</g>\n",
       "<!-- 44&#45;&gt;43 -->\n",
       "<g id=\"edge43\" class=\"edge\">\n",
       "<title>44&#45;&gt;43</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1155.5021,-85.7616C1163.2236,-73.9036 1173.4268,-58.2345 1182.0765,-44.951\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1185.2432,-46.502 1187.7669,-36.2121 1179.3772,-42.6822 1185.2432,-46.502\"/>\n",
       "<text text-anchor=\"middle\" x=\"1191.1777\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 45 -->\n",
       "<g id=\"node45\" class=\"node\">\n",
       "<title>45</title>\n",
       "<text text-anchor=\"middle\" x=\"1296.626\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">45 (into)</text>\n",
       "</g>\n",
       "<!-- 46&#45;&gt;45 -->\n",
       "<g id=\"edge44\" class=\"edge\">\n",
       "<title>46&#45;&gt;45</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1279.2916,-85.7616C1282.2376,-74.2456 1286.103,-59.1353 1289.436,-46.1064\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1292.8795,-46.7676 1291.9671,-36.2121 1286.0979,-45.0327 1292.8795,-46.7676\"/>\n",
       "<text text-anchor=\"middle\" x=\"1299.6709\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x11dc61e10>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = graphviz.Source(list(horror10Parse[0])[0].to_dot())\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same plot summary, I will try to parse the second sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She has to get 10 points , and during a conversation with a fellow demon on her hell phone gets her first point by telling a mother her baby is ugly and causing her to hate it .\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(horrorDF['sentences'].iloc[10][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the dependency tree of the same plot but the second sentences: for the second sentence, it is relatively shorter and thus have 8 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "horror10Parse = list(stanford.depParser.parse_sents(horrorDF['sentences'].iloc[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"916pt\" height=\"646pt\"\n",
       " viewBox=\"0.00 0.00 915.97 646.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 642)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-642 911.9673,-642 911.9673,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"675.188\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"675.188\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2 (has)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M675.188,-601.7616C675.188,-590.3597 675.188,-575.4342 675.188,-562.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"678.6881,-562.2121 675.188,-552.2121 671.6881,-562.2121 678.6881,-562.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"686.4639\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"516.188\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 (She)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M647.5908,-522.3211C632.3967,-515.6425 613.3332,-506.852 596.8501,-498 581.9662,-490.0069 566.0646,-480.3952 552.3484,-471.7439\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"553.9978,-468.6448 543.6832,-466.2242 550.237,-474.5488 553.9978,-468.6448\"/>\n",
       "<text text-anchor=\"middle\" x=\"612.3569\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>20</title>\n",
       "<text text-anchor=\"middle\" x=\"595.188\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">20 (gets)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;20 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M658.222,-515.7616C646.8731,-503.5615 631.7716,-487.3273 619.1951,-473.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"621.5032,-471.1501 612.1295,-466.2121 616.3779,-475.9179 621.5032,-471.1501\"/>\n",
       "<text text-anchor=\"middle\" x=\"652.2397\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conj</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"739.188\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4 (get)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M688.7607,-515.7616C697.6702,-503.7896 709.4705,-487.9328 719.4161,-474.5685\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"722.4725,-476.324 725.6348,-466.2121 716.8568,-472.1449 722.4725,-476.324\"/>\n",
       "<text text-anchor=\"middle\" x=\"730.2397\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">xcomp</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"812.188\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">8 (and)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;8 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M702.4796,-523.5475C717.8967,-517.1243 737.218,-508.1848 753.188,-498 764.6216,-490.7083 776.217,-481.3875 786.0668,-472.7736\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"788.4396,-475.3471 793.5555,-466.0693 783.7705,-470.1317 788.4396,-475.3471\"/>\n",
       "<text text-anchor=\"middle\" x=\"778.4019\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cc</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<text text-anchor=\"middle\" x=\"149.188\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">11 (conversation)</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;11 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>20&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M562.446,-433.0918C559.351,-431.9492 556.2325,-430.8947 553.188,-430 491.3173,-411.8181 314.3964,-385.276 216.4551,-371.3397\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"216.7546,-367.8472 206.3622,-369.9084 215.7717,-374.7779 216.7546,-367.8472\"/>\n",
       "<text text-anchor=\"middle\" x=\"484.1328\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>19</title>\n",
       "<text text-anchor=\"middle\" x=\"449.188\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">19 (phone)</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;19 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>20&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M564.2888,-429.8869C554.5465,-424.1701 543.7457,-417.826 533.8501,-412 518.9883,-403.2502 502.6708,-393.6191 488.3613,-385.1651\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"490.1319,-382.146 479.7421,-380.0718 486.5707,-388.1725 490.1319,-382.146\"/>\n",
       "<text text-anchor=\"middle\" x=\"549.3569\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>25</title>\n",
       "<text text-anchor=\"middle\" x=\"545.188\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">25 (telling)</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;25 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>20&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M584.5843,-429.7616C577.6901,-417.9036 568.5801,-402.2345 560.8572,-388.951\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"563.8285,-387.098 555.7764,-380.2121 557.7769,-390.6164 563.8285,-387.098\"/>\n",
       "<text text-anchor=\"middle\" x=\"588.3467\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advcl</text>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>23</title>\n",
       "<text text-anchor=\"middle\" x=\"675.188\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">23 (point)</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;23 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>20&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M612.1539,-429.7616C623.5028,-417.5615 638.6044,-401.3273 651.1809,-387.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"653.9981,-389.9179 658.2465,-380.2121 648.8728,-385.1501 653.9981,-389.9179\"/>\n",
       "<text text-anchor=\"middle\" x=\"652.6328\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"756.188\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3 (to)</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;3 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>4&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M742.7933,-429.7616C745.0697,-418.2456 748.0566,-403.1353 750.6321,-390.1064\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"754.0822,-390.701 752.5879,-380.2121 747.2151,-389.3435 754.0822,-390.701\"/>\n",
       "<text text-anchor=\"middle\" x=\"763.5708\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"855.188\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6 (points)</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M763.5054,-429.9716C780.6737,-417.2433 803.8677,-400.0478 822.631,-386.1371\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"824.9539,-388.7719 830.9026,-380.0047 820.785,-383.1487 824.9539,-388.7719\"/>\n",
       "<text text-anchor=\"middle\" x=\"816.6328\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"860.188\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5 (10)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;5 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>6&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M856.2484,-343.7616C856.9113,-332.3597 857.779,-317.4342 858.5314,-304.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"862.0427,-304.3984 859.1291,-294.2121 855.0545,-303.9921 862.0427,-304.3984\"/>\n",
       "<text text-anchor=\"middle\" x=\"883.0776\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nummod</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"36.188\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">9 (during)</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"117.188\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">10 (a)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>11&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M125.4995,-343.9716C108.7751,-331.2433 86.181,-314.0478 67.903,-300.1371\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"69.9226,-297.2758 59.8453,-294.0047 65.6832,-302.8461 69.9226,-297.2758\"/>\n",
       "<text text-anchor=\"middle\" x=\"112.2329\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>11&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142.4016,-343.7616C138.0742,-332.1316 132.3827,-316.8357 127.5024,-303.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"130.7323,-302.3637 123.9646,-294.2121 124.1717,-304.8049 130.7323,-302.3637\"/>\n",
       "<text text-anchor=\"middle\" x=\"143.7397\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>15</title>\n",
       "<text text-anchor=\"middle\" x=\"202.188\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">15 (demon)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;15 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>11&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M160.4279,-343.7616C167.7358,-331.9036 177.3923,-316.2345 185.5786,-302.951\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"188.6973,-304.5616 190.9643,-294.2121 182.7381,-300.889 188.6973,-304.5616\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.1328\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"39.188\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">12 (with)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>15&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M162.9573,-257.8294C151.33,-252.273 138.6267,-246.0326 127.0981,-240 111.1231,-231.6407 93.8193,-221.9426 78.823,-213.3248\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.226,-210.0932 69.8165,-208.1202 76.7236,-216.154 80.226,-210.0932\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.2329\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>13</title>\n",
       "<text text-anchor=\"middle\" x=\"118.188\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">13 (a)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>15&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M184.3737,-257.7616C172.346,-245.4475 156.304,-229.0235 143.0259,-215.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"145.4678,-212.9203 135.9765,-208.2121 140.4601,-217.8115 145.4678,-212.9203\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.7397\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"202.188\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">14 (fellow)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>15&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M202.188,-257.7616C202.188,-246.3597 202.188,-231.4342 202.188,-218.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"205.6881,-218.2121 202.188,-208.2121 198.6881,-218.2121 205.6881,-218.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"217.7397\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>18</title>\n",
       "<text text-anchor=\"middle\" x=\"291.188\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">18 (hell)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;18 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>15&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M221.0626,-257.7616C233.8063,-245.4475 250.8032,-229.0235 264.8716,-215.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"267.5814,-217.6779 272.3406,-208.2121 262.7172,-212.644 267.5814,-217.6779\"/>\n",
       "<text text-anchor=\"middle\" x=\"268.1328\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>16</title>\n",
       "<text text-anchor=\"middle\" x=\"214.188\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">16 (on)</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>18&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M274.8583,-171.7616C263.9349,-159.5615 249.3997,-143.3273 237.2948,-129.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"239.7722,-127.3276 230.4942,-122.2121 234.5571,-131.9969 239.7722,-127.3276\"/>\n",
       "<text text-anchor=\"middle\" x=\"270.2329\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"291.188\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">17 (her)</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;17 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>18&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M291.188,-171.7616C291.188,-160.3597 291.188,-145.4342 291.188,-132.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"294.6881,-132.2121 291.188,-122.2121 287.6881,-132.2121 294.6881,-132.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"321.5259\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod:poss</text>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>24</title>\n",
       "<text text-anchor=\"middle\" x=\"340.188\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">24 (by)</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;24 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>25&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M505.9014,-347.2487C502.9535,-346.1476 500.0241,-345.0552 497.188,-344 475.5351,-335.944 469.8088,-334.7386 448.4224,-326 418.9291,-313.9489 410.0491,-309.4485 378.0062,-294.3541\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"379.3688,-291.1273 368.8298,-290.0408 376.391,-297.4623 379.3688,-291.1273\"/>\n",
       "<text text-anchor=\"middle\" x=\"463.5708\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 33 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>33</title>\n",
       "<text text-anchor=\"middle\" x=\"429.188\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">33 (causing)</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;33 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>25&#45;&gt;33</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M520.8706,-343.9716C503.7022,-331.2433 480.5083,-314.0478 461.745,-300.1371\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"463.591,-297.1487 453.4734,-294.0047 459.422,-302.7719 463.591,-297.1487\"/>\n",
       "<text text-anchor=\"middle\" x=\"506.2397\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conj</text>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>27</title>\n",
       "<text text-anchor=\"middle\" x=\"531.188\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">27 (mother)</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;27 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>25&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M542.2189,-343.7616C540.3443,-332.2456 537.8844,-317.1353 535.7634,-304.1064\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"539.2141,-303.5198 534.1527,-294.2121 532.3051,-304.6446 539.2141,-303.5198\"/>\n",
       "<text text-anchor=\"middle\" x=\"551.6328\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 32 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>32</title>\n",
       "<text text-anchor=\"middle\" x=\"622.188\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">32 (and)</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;32 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>25&#45;&gt;32</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M561.5177,-343.7616C572.441,-331.5615 586.9763,-315.3273 599.0812,-301.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"601.8189,-303.9969 605.8818,-294.2121 596.6037,-299.3276 601.8189,-303.9969\"/>\n",
       "<text text-anchor=\"middle\" x=\"595.4019\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cc</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>21</title>\n",
       "<text text-anchor=\"middle\" x=\"702.188\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">21 (her)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;21 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>23&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M680.914,-343.7616C684.5295,-332.2456 689.2734,-317.1353 693.3639,-304.1064\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"696.8141,-304.8014 696.4702,-294.2121 690.1355,-302.7045 696.8141,-304.8014\"/>\n",
       "<text text-anchor=\"middle\" x=\"721.5259\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod:poss</text>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>22</title>\n",
       "<text text-anchor=\"middle\" x=\"783.188\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">22 (first)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;22 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>23&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M711.1674,-347.2719C731.0427,-338.9137 752.4617,-329.4502 756.188,-326 762.9518,-319.7374 768.3751,-311.3854 772.5353,-303.3036\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"775.7818,-304.6233 776.8434,-294.0818 769.4397,-301.6605 775.7818,-304.6233\"/>\n",
       "<text text-anchor=\"middle\" x=\"782.7397\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 36 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>36</title>\n",
       "<text text-anchor=\"middle\" x=\"375.188\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">36 (hate)</text>\n",
       "</g>\n",
       "<!-- 33&#45;&gt;36 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>33&#45;&gt;36</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M412.3178,-257.63C407.7286,-252.1704 402.9602,-246.0316 399.0845,-240 394.5499,-232.943 390.3322,-224.8933 386.7416,-217.3456\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"389.8883,-215.8103 382.5522,-208.1662 383.5201,-218.7168 389.8883,-215.8103\"/>\n",
       "<text text-anchor=\"middle\" x=\"418.2397\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">xcomp</text>\n",
       "</g>\n",
       "<!-- 34 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>34</title>\n",
       "<text text-anchor=\"middle\" x=\"456.188\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">34 (her)</text>\n",
       "</g>\n",
       "<!-- 33&#45;&gt;34 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>33&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M434.914,-257.7616C438.5295,-246.2456 443.2734,-231.1353 447.3639,-218.1064\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"450.8141,-218.8014 450.4702,-208.2121 444.1355,-216.7045 450.8141,-218.8014\"/>\n",
       "<text text-anchor=\"middle\" x=\"457.6328\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>26</title>\n",
       "<text text-anchor=\"middle\" x=\"531.188\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">26 (a)</text>\n",
       "</g>\n",
       "<!-- 27&#45;&gt;26 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>27&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M531.188,-257.7616C531.188,-246.3597 531.188,-231.4342 531.188,-218.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"534.6881,-218.2121 531.188,-208.2121 527.6881,-218.2121 534.6881,-218.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"539.7397\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 31 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>31</title>\n",
       "<text text-anchor=\"middle\" x=\"610.188\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">31 (ugly)</text>\n",
       "</g>\n",
       "<!-- 27&#45;&gt;31 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>27&#45;&gt;31</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M547.9419,-257.7616C559.1489,-245.5615 574.0617,-229.3273 586.481,-215.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"589.2708,-217.9443 593.4583,-208.2121 584.1157,-213.2088 589.2708,-217.9443\"/>\n",
       "<text text-anchor=\"middle\" x=\"598.7261\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>29</title>\n",
       "<text text-anchor=\"middle\" x=\"563.188\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">29 (baby)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;29 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>31&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M600.2205,-171.7616C593.8023,-160.0176 585.3411,-144.5355 578.1268,-131.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"581.0081,-129.3087 573.1411,-122.2121 574.8656,-132.6657 581.0081,-129.3087\"/>\n",
       "<text text-anchor=\"middle\" x=\"605.3569\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>30</title>\n",
       "<text text-anchor=\"middle\" x=\"643.188\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">30 (is)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;30 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>31&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M617.1864,-171.7616C621.6491,-160.1316 627.5185,-144.8357 632.5512,-131.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"635.8847,-132.8023 636.1996,-122.2121 629.3494,-130.2945 635.8847,-132.8023\"/>\n",
       "<text text-anchor=\"middle\" x=\"639.2949\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cop</text>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>28</title>\n",
       "<text text-anchor=\"middle\" x=\"563.188\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">28 (her)</text>\n",
       "</g>\n",
       "<!-- 29&#45;&gt;28 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>29&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M563.188,-85.7616C563.188,-74.3597 563.188,-59.4342 563.188,-46.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"566.6881,-46.2121 563.188,-36.2121 559.6881,-46.2121 566.6881,-46.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"593.5259\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod:poss</text>\n",
       "</g>\n",
       "<!-- 35 -->\n",
       "<g id=\"node36\" class=\"node\">\n",
       "<title>35</title>\n",
       "<text text-anchor=\"middle\" x=\"375.188\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">35 (to)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;35 -->\n",
       "<g id=\"edge36\" class=\"edge\">\n",
       "<title>36&#45;&gt;35</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M375.188,-171.7616C375.188,-160.3597 375.188,-145.4342 375.188,-132.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"378.6881,-132.2121 375.188,-122.2121 371.6881,-132.2121 378.6881,-132.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"389.5708\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 37 -->\n",
       "<g id=\"node37\" class=\"node\">\n",
       "<title>37</title>\n",
       "<text text-anchor=\"middle\" x=\"447.188\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">37 (it)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;37 -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>36&#45;&gt;37</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M392.2625,-171.9382C397.471,-166.2792 403.1499,-159.955 408.188,-154 414.5586,-146.47 421.2469,-138.0865 427.2503,-130.3692\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"430.1152,-132.3854 433.4483,-122.3285 424.5711,-128.1119 430.1152,-132.3854\"/>\n",
       "<text text-anchor=\"middle\" x=\"432.6328\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x11dbfa4a8>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = graphviz.Source(list(horror10Parse[1])[0].to_dot())\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I randomly choose another number, so this time, I will parse the twentieth plot summary in my horror film corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "horror20Parse = list(stanford.depParser.parse_sents(horrorDF['sentences'].iloc[20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly review the text again, and we could see this time its a relatively shorter and simpler sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It 's always just a party- until somebody gets killed !\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(horrorDF['sentences'].iloc[20][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the dependency tree, we see that for this simple sentence, the layer is significantly smaller and has become 4 layers only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"550pt\" height=\"302pt\"\n",
       " viewBox=\"0.00 0.00 550.19 302.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 298)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-298 546.188,-298 546.188,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"222\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"222\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6 (party&#45;)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;6 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M222,-257.7616C222,-246.3597 222,-231.4342 222,-218.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"225.5001,-218.2121 222,-208.2121 218.5001,-218.2121 225.5001,-218.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"233.2759\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 (It)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>6&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M187.0262,-180.1587C165.7187,-173.7023 138.1624,-164.5221 114.6621,-154 97.1508,-146.1594 78.5802,-135.8776 63.061,-126.6777\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"64.6805,-123.5675 54.3071,-121.4126 61.0726,-129.5661 64.6805,-123.5675\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.1689\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2 (&#39;s)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;2 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M194.2677,-171.9101C185.7239,-166.25 176.3216,-159.9321 167.7861,-154 155.9035,-145.7415 143.0364,-136.4774 131.6807,-128.1882\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"133.4681,-125.1589 123.3328,-122.0723 129.3311,-130.8057 133.4681,-125.1589\"/>\n",
       "<text text-anchor=\"middle\" x=\"178.1069\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cop</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"181\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3 (always)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;3 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>6&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M207.8506,-171.9771C203.9344,-166.4248 199.9309,-160.1497 196.8965,-154 193.4605,-147.0364 190.5501,-139.166 188.1962,-131.7649\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.5279,-130.6886 185.3344,-122.0926 184.8155,-132.6748 191.5279,-130.6886\"/>\n",
       "<text text-anchor=\"middle\" x=\"219.5518\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advmod</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"264\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4 (just)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;4 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>6&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M232.5064,-171.8603C235.6694,-166.1981 239.0751,-159.8917 242,-154 245.5371,-146.8752 249.118,-139.0519 252.3344,-131.7525\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"255.6924,-132.8056 256.456,-122.2383 249.2692,-130.023 255.6924,-132.8056\"/>\n",
       "<text text-anchor=\"middle\" x=\"271.5518\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advmod</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"337\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5 (a)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;5 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>6&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M256.8767,-177.5357C270.5302,-171.658 285.8075,-163.7666 298,-154 306.1626,-147.4615 313.6377,-138.8903 319.8115,-130.6954\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"322.7789,-132.5628 325.7485,-122.3927 317.0848,-128.4912 322.7789,-132.5628\"/>\n",
       "<text text-anchor=\"middle\" x=\"320.5518\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"419\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">10 (killed)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;10 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>6&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M256.7127,-180.8088C278.963,-174.4171 308.2137,-165.0726 333,-154 349.7148,-146.5331 367.3322,-136.6774 382.239,-127.6912\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"384.4405,-130.447 391.138,-122.2375 380.7829,-124.4786 384.4405,-130.447\"/>\n",
       "<text text-anchor=\"middle\" x=\"375.1587\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advcl</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"324\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">7 (until)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;7 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>10&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M398.8529,-85.7616C385.1242,-73.3335 366.771,-56.719 351.6742,-43.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"353.8805,-40.3286 344.118,-36.2121 349.1826,-45.518 353.8805,-40.3286\"/>\n",
       "<text text-anchor=\"middle\" x=\"392.3828\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"419\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">8 (somebody)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>10&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M419,-85.7616C419,-74.3597 419,-59.4342 419,-46.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"422.5001,-46.2121 419,-36.2121 415.5001,-46.2121 422.5001,-46.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"446.2241\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubjpass</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"513\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">9 (gets)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;9 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>10&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M453.1154,-85.9065C461.3933,-80.7094 469.8968,-74.6323 477,-68 484.2343,-61.2452 490.9422,-52.8412 496.5591,-44.8626\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"499.5262,-46.7223 502.1991,-36.4701 493.7163,-42.8178 499.5262,-46.7223\"/>\n",
       "<text text-anchor=\"middle\" x=\"511.1621\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">auxpass</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x11da7c6a0>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphviz.Source(list(horror20Parse[0])[0].to_dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, we could claim the parse depth is positively related to the sentence complexity. The greater the path depth, the more the sentence complexity, or the less parse depth, the simplier the sentence complexity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are five things you can extract from these parses for subsequent analysis? (e.g., nouns collocated in a noun phrase; adjectives that modify a noun; etc.) Capture these sets of things for a focal set of words (e.g., \"Bush\", \"Obama\", \"Trump\"). What do they reveal about the roles that these entities are perceived to play in the social world inscribed by your texts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these parses, I can extract nouns collocated in a noun phrase, adjectives that modify a noun, verbs related to a noun, nouns related to an adjective, and adverbs that modify a verb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will first try to parse the whole dataset and attempt to capture these sets of things for some words to see what we can find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "horrorTree = []\n",
    "for i in range(len(horrorDF['sentences'])):\n",
    "    horrorParses = list(stanford.parser.parse_sents(horrorDF['sentences'].iloc[i]))\n",
    "    for j in range(len(horrorParses)):\n",
    "        HorrorSentParseTree = list(horrorParses[j]) \n",
    "        horrorTree += HorrorSentParseTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate the process, two functions would be created: 'findRelation' is created to find part of the speech related to the targets and 'findSubrelation' is composed to find part of speech subrelated to the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findRelation(parsetree, relationType, *targets):\n",
    "    x = 0\n",
    "    for i in range(len(parsetree)):\n",
    "        r = treeRelation(parsetree[i], relationType, *targets)\n",
    "        if r != []:\n",
    "            x += 1\n",
    "            print(i, r)\n",
    "    if x == 0:\n",
    "        print('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findSubrelation(parsetree, relationTypeScope, relationTypeTarget, *targets):\n",
    "    x = 0\n",
    "    for i in range(len(parsetree)):\n",
    "        r = treeSubRelation(parsetree[i], relationTypeScope, relationTypeTarget, *targets)\n",
    "        if r != [] and r != set():\n",
    "            x += 1\n",
    "            print(i, r)\n",
    "    if x == 0:\n",
    "        print('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract nouns collocated in a noun phrase: because these are horror movies, I am interested to see whether there are any nouns collocated in the noun \"killer\" since this matches the theme of many horror movies. The output shows many interesting results, such collocation include: \"serial killer' and even \"vampire serial killer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 [[('NP', 'a killer')]]\n",
      "118 [[('NP', 'a serial killer')]]\n",
      "182 [[('NP', 'the killer')]]\n",
      "183 [[('NP', 'The story of a serial killer , a sick a depraved man who enjoys the misery of others .')], [('NP', 'The story of a serial killer')], [('NP', 'a serial killer')]]\n",
      "204 [[('NP', 'a killer')]]\n",
      "256 [[('NP', 'the voice of the killer')], [('NP', 'the killer')]]\n",
      "319 [[('NP', 'bloodthirsty creatures killer')]]\n",
      "360 [[('NP', 'two young documentarians , who seek to tell this suburban legend from all sides while getting some killer footage')], [('NP', 'some killer footage')]]\n",
      "362 [[('NP', 'this his killer is looking for him next victim')], [('NP', 'this his killer is looking for him')], [('NP', 'his killer')]]\n",
      "367 [[('NP', 'the path of a notorious serial killer')], [('NP', 'a notorious serial killer')]]\n",
      "416 [[('NP', 'Samuel , a serial killer and the feral boy-dog')], [('NP', 'a serial killer')]]\n",
      "487 [[('NP', 'a vampire serial killer')]]\n"
     ]
    }
   ],
   "source": [
    "findRelation(horrorTree, 'NP', 'killer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all of the adjectives within the noun phrase defined by \"killer\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 {'serial'}\n",
      "183 {'depraved', 'sick', 'serial'}\n",
      "319 {'bloodthirsty'}\n",
      "360 {'young', 'suburban'}\n",
      "362 {'next'}\n",
      "367 {'notorious', 'serial'}\n",
      "416 {'feral', 'serial'}\n",
      "487 {'serial', 'vampire'}\n"
     ]
    }
   ],
   "source": [
    "findSubrelation(horrorTree, 'NP', 'JJ', 'killer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract adjectives that modify a noun: man vs. woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 [[('ADJP', 'safe from this ex-Special Forces mad man with a big knife')]]\n",
      "130 [[('ADJP', 'delve into the life of a frightened man')]]\n"
     ]
    }
   ],
   "source": [
    "findRelation(horrorTree, 'ADJP', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 {'safe', 'big', 'mad', 'ex-Special'}\n",
      "130 {'delve', 'frightened'}\n"
     ]
    }
   ],
   "source": [
    "findSubrelation(horrorTree, 'ADJP', 'JJ', 'man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find verbs related to a noun: he vs. she"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [[('VP', 'will do anything he can to immerse himself in his desired role')], [('VP', 'do anything he can to immerse himself in his desired role')]]\n",
      "10 [[('VP', 'can find out what he took and how to stop it')], [('VP', 'find out what he took and how to stop it')]]\n",
      "12 [[('VP', 'ditches his car to take refuge in a nearby 24 hour diner , where he discovers the love of his life : Jessica')], [('VP', 'to take refuge in a nearby 24 hour diner , where he discovers the love of his life : Jessica')], [('VP', 'take refuge in a nearby 24 hour diner , where he discovers the love of his life : Jessica')]]\n",
      "40 [[('VP', \"Stuck with no money until local mechanic Hector offers them a deal - play his annual beach party and he 'll fix their van for free\")], [('VP', \"offers them a deal - play his annual beach party and he 'll fix their van for free\")]]\n",
      "52 [[('VP', 'finds the iPhone prototype and rather than return it , the demon suggests in his ear that he could make a lot of money by selling it to Gizmodo')], [('VP', 'suggests in his ear that he could make a lot of money by selling it to Gizmodo')]]\n",
      "89 [[('VP', 'unfolds through two characters - a lone special operations soldier who has been separated from the rest of his team , and a young girl who he encounters while trying to survive the hostile yet desolate landscape')]]\n",
      "91 [[('VP', 'realizes that he must protect the girl from the dangers lurking around them')]]\n",
      "92 [[('VP', 'becomes apparent that he must not only teach the girl how to defend herself , but also prepare her for the inevitability that he can not protect her for much longer')], [('VP', 'must not only teach the girl how to defend herself , but also prepare her for the inevitability that he can not protect her for much longer')], [('VP', 'teach the girl how to defend herself , but also prepare her for the inevitability that he can not protect her for much longer')], [('VP', 'to defend herself , but also prepare her for the inevitability that he can not protect her for much longer')], [('VP', 'defend herself , but also prepare her for the inevitability that he can not protect her for much longer')], [('VP', 'prepare her for the inevitability that he can not protect her for much longer')]]\n",
      "109 [[('VP', 'will not rest until he completes his twisted mission : kill everything')], [('VP', 'rest until he completes his twisted mission : kill everything')], [('VP', 'rest until he completes his twisted mission')]]\n",
      "132 [[('VP', 'is , until he finds a mysterious suitcase on his doorstep')]]\n",
      "133 [[('VP', 'begins to take a bizarre turn as he is plagued by a mysterious force inside the case , bringing out the inner evils that only that dark side of man is capable of')], [('VP', 'to take a bizarre turn as he is plagued by a mysterious force inside the case')], [('VP', 'take a bizarre turn as he is plagued by a mysterious force inside the case')]]\n",
      "140 [[('VP', \"makes it clear that he wants to 'do things ' his way , and that no one can keep him locked up forever\")]]\n",
      "155 [[('VP', 'must have the color variants , the rarities , the 1950s originals : every food he can find , and keep , in mint condition')], [('VP', 'have the color variants , the rarities , the 1950s originals : every food he can find , and keep , in mint condition')]]\n",
      "158 [[('VP', \"is too busy searching for the alien he 's sure attacked him once\")], [('VP', \"searching for the alien he 's sure attacked him once\")]]\n",
      "165 [[('VP', 'realizes he himself')]]\n",
      "187 [[('VP', 'is Polly , a girl he would keep captive for 186 days breaking her down physically and mentally')]]\n",
      "197 [[('VP', 'discover the dark force that has entered his life and evade his own destruction or will he too fall victim')], [('VP', 'evade his own destruction or will he too fall victim')], [('VP', 'will he too fall victim')]]\n",
      "199 [[('VP', 'tries to keep his mind occupied from an injury he suffered at work')], [('VP', 'to keep his mind occupied from an injury he suffered at work')], [('VP', 'keep his mind occupied from an injury he suffered at work')]]\n",
      "278 [[('VP', 'asked Jack and he had to rip')]]\n",
      "331 [[('VP', 'is sympathetic to humans and sees his work as a way of alleviating their suffering but his views on finding a solution change considerably when he meets someone who found a way to transform himself from being a vampire to again take human form')], [('VP', 'sees his work as a way of alleviating their suffering but his views on finding a solution change considerably when he meets someone who found a way to transform himself from being a vampire to again take human form')], [('VP', 'alleviating their suffering but his views on finding a solution change considerably when he meets someone who found a way to transform himself from being a vampire to again take human form')], [('VP', 'finding a solution change considerably when he meets someone who found a way to transform himself from being a vampire to again take human form')]]\n",
      "333 [[('VP', 'takes us to an L.A. bistro , where not so famous film director Elliot begs Rose , the star he helped discover , to be in his next movie')], [('VP', 'begs Rose , the star he helped discover , to be in his next movie')]]\n",
      "339 [[('VP', 'ensues as Bob tries to prevent them from getting to his beer until he realizes that they are really after his wife and kids')], [('VP', 'tries to prevent them from getting to his beer until he realizes that they are really after his wife and kids')], [('VP', 'to prevent them from getting to his beer until he realizes that they are really after his wife and kids')], [('VP', 'prevent them from getting to his beer until he realizes that they are really after his wife and kids')]]\n",
      "352 [[('VP', 'grows obsessed with Claire , to the point where he becomes a danger to them both')], [('VP', 'obsessed with Claire , to the point where he becomes a danger to them both')]]\n",
      "361 [[('VP', 'named Brandon who is housesitting for his mother when he makes an unlikely ally-a ghost in the form of a disembodied voice in his head')], [('VP', 'is housesitting for his mother when he makes an unlikely ally-a ghost in the form of a disembodied voice in his head')], [('VP', 'housesitting for his mother when he makes an unlikely ally-a ghost in the form of a disembodied voice in his head')]]\n",
      "406 [[('VP', 'arrives at the notorious House of Usher , whereupon he is greeted by old acquaintances Roderick and Madeline Usher and their servant , Markus')]]\n",
      "407 [[('VP', 'begins to realize that he is in mortal danger')], [('VP', 'to realize that he is in mortal danger')], [('VP', 'realize that he is in mortal danger')]]\n",
      "414 [[('VP', 'decides to investigate how he died')], [('VP', 'to investigate how he died')], [('VP', 'investigate how he died')]]\n",
      "430 [[('VP', 'comes home as if he had never left ... 30 years earlier')]]\n",
      "443 [[('VP', 'set in his bedroom and a woman from his past haunts the cemetery where he lies buried')]]\n",
      "458 [[('VP', 'must stop the tradition he spent his life protecting')], [('VP', 'stop the tradition he spent his life protecting')]]\n",
      "489 [[('VP', \"be able to find what he 's looking for and salvage his relationship with Fran\")], [('VP', \"to find what he 's looking for and salvage his relationship with Fran\")], [('VP', \"find what he 's looking for and salvage his relationship with Fran\")], [('VP', \"find what he 's looking for\")]]\n"
     ]
    }
   ],
   "source": [
    "findRelation(horrorTree, 'VP', 'he')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 {'discovers', 'ditches'}\n",
      "40 {'offers'}\n",
      "52 {'finds', 'suggests'}\n",
      "89 {'unfolds', 'has', 'encounters'}\n",
      "91 {'realizes'}\n",
      "92 {'becomes'}\n",
      "109 {'completes'}\n",
      "132 {'finds', 'is'}\n",
      "133 {'is', 'begins'}\n",
      "140 {'makes', 'wants'}\n",
      "158 {'is', \"'s\"}\n",
      "165 {'realizes'}\n",
      "187 {'is'}\n",
      "197 {'has'}\n",
      "199 {'tries'}\n",
      "331 {'sees', 'is', 'meets'}\n",
      "333 {'takes', 'begs'}\n",
      "339 {'realizes', 'tries', 'ensues'}\n",
      "352 {'becomes', 'grows'}\n",
      "361 {'is', 'makes'}\n",
      "406 {'arrives', 'is'}\n",
      "407 {'is', 'begins'}\n",
      "414 {'decides'}\n",
      "430 {'comes'}\n",
      "443 {'lies'}\n",
      "489 {\"'s\"}\n"
     ]
    }
   ],
   "source": [
    "find_subrelation(horrorTree, 'VP', 'VBZ', 'he')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 [[('VP', 'has no idea she is about to be part of that plan')]]\n",
      "61 [[('VP', 'tells a woman to check out her room and when she does she discovers her husband has been having an affair')], [('VP', 'does she discovers her husband has been having an affair')]]\n",
      "66 [[('VP', 'confronts the demon , having realized what she is up to')], [('VP', 'having realized what she is up to')], [('VP', 'realized what she is up to')]]\n",
      "67 [[('VP', \"tries to deny it , then bribe her with winning lottery numbers which turn out to be only the numbers from `` Lost '' which she recognizes\")], [('VP', \"to deny it , then bribe her with winning lottery numbers which turn out to be only the numbers from `` Lost '' which she recognizes\")], [('VP', \"deny it , then bribe her with winning lottery numbers which turn out to be only the numbers from `` Lost '' which she recognizes\")], [('VP', \"bribe her with winning lottery numbers which turn out to be only the numbers from `` Lost '' which she recognizes\")], [('VP', \"turn out to be only the numbers from `` Lost '' which she recognizes\")], [('VP', \"to be only the numbers from `` Lost '' which she recognizes\")], [('VP', \"be only the numbers from `` Lost '' which she recognizes\")]]\n",
      "70 [[('VP', 'is locked in despair , sure she will never earn her horns')], [('VP', 'locked in despair , sure she will never earn her horns')]]\n",
      "103 [[('VP', 'has the sensation that someone is stalking her and she goes to the police station and reports to Chief Dinneli')], [('VP', 'has the sensation that someone is stalking her and she goes to the police station')]]\n",
      "106 [[('VP', 'learns that she is in the house of evil and nothing is like she thought it would be')], [('VP', 'is in the house of evil and nothing is like she thought it would be')], [('VP', 'is like she thought it would be')]]\n",
      "164 [[('VP', \"tries to comfort the naive and nervous Babe before she enthralls in her 'first time\")], [('VP', \"to comfort the naive and nervous Babe before she enthralls in her 'first time\")], [('VP', \"comfort the naive and nervous Babe before she enthralls in her 'first time\")]]\n",
      "188 [[('VP', 'is though is that regardless of the torture she endures at his hand')], [('VP', 'is that regardless of the torture she endures at his hand')]]\n",
      "228 [[('VP', \"is the night she 's hunting down her cheating hubby and reclaiming her marriage\")]]\n",
      "314 [[('VP', 'takes a job at a local blood clinic so she can steal samples and avoid hurting anyone')]]\n",
      "315 [[('VP', 'must decide between being outed at work , and accepting herself for who she is')], [('VP', 'decide between being outed at work , and accepting herself for who she is')], [('VP', 'being outed at work , and accepting herself for who she is')], [('VP', 'accepting herself for who she is')]]\n",
      "342 [[('VP', 'needing desperately to convince her superior that she is indeed capable of making tough decisions')], [('VP', 'to convince her superior that she is indeed capable of making tough decisions')], [('VP', 'convince her superior that she is indeed capable of making tough decisions')]]\n",
      "349 [[('VP', 'convinces her jobless , volatile boyfriend Dustin to help her pull an inside job at the bank where she works')], [('VP', 'to help her pull an inside job at the bank where she works')], [('VP', 'help her pull an inside job at the bank where she works')], [('VP', 'pull an inside job at the bank where she works')]]\n",
      "462 [[('VP', 'is haunted by a spirit that she believes')], [('VP', 'haunted by a spirit that she believes')]]\n",
      "487 [[('VP', 'turns to his girlfriend Fran only to find out that she just may be a vampire serial killer')], [('VP', 'to find out that she just may be a vampire serial killer')], [('VP', 'find out that she just may be a vampire serial killer')]]\n"
     ]
    }
   ],
   "source": [
    "findRelation(horrorTree, 'VP', 'she')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 {'has', 'is'}\n",
      "61 {'discovers', 'has', 'does', 'tells'}\n",
      "66 {'is', 'confronts'}\n",
      "67 {'recognizes', 'tries'}\n",
      "70 {'is'}\n",
      "103 {'goes', 'has', 'is', 'reports'}\n",
      "106 {'is', 'learns'}\n",
      "164 {'enthralls', 'tries'}\n",
      "188 {'endures', 'is'}\n",
      "228 {'is', \"'s\"}\n",
      "314 {'takes'}\n",
      "315 {'is'}\n",
      "342 {'is'}\n",
      "349 {'convinces', 'works'}\n",
      "462 {'is', 'believes'}\n",
      "487 {'turns'}\n"
     ]
    }
   ],
   "source": [
    "find_subrelation(horrorTree, 'VP', 'VBZ', 'she')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all nouns related to an adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 [[('NP', 'no antidote for the victims who are doomed to die or become incurably mad')], [('NP', 'the victims who are doomed to die or become incurably mad')]]\n",
      "112 [[('NP', 'this ex-Special Forces mad man with a big knife')], [('NP', 'this ex-Special Forces mad man')]]\n",
      "125 [[('NP', \"this mad individual 's evil plan\")], [('NP', \"this mad individual 's\")]]\n",
      "142 [[('NP', 'the mentally ill who have become victims of unethical procedures and mad doctors')], [('NP', 'victims of unethical procedures and mad doctors')], [('NP', 'unethical procedures and mad doctors')], [('NP', 'mad doctors')]]\n"
     ]
    }
   ],
   "source": [
    "findRelation(horrorTree, 'NP', 'mad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 {'antidote'}\n",
      "112 {'knife', 'man'}\n",
      "125 {'plan', 'individual'}\n"
     ]
    }
   ],
   "source": [
    "findSubrelation(horrorTree, 'NP', 'NN', 'mad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adverbs that modify a verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 [[('VP', 'unfolds through two characters - a lone special operations soldier who has been separated from the rest of his team , and a young girl who he encounters while trying to survive the hostile yet desolate landscape')], [('VP', 'encounters while trying to survive the hostile yet desolate landscape')], [('VP', 'trying to survive the hostile yet desolate landscape')], [('VP', 'to survive the hostile yet desolate landscape')], [('VP', 'survive the hostile yet desolate landscape')]]\n",
      "125 [[('VP', \"survive this mad individual 's evil plan\")]]\n",
      "188 [[('VP', 'does nothing but increase her will to survive')], [('VP', 'increase her will to survive')], [('VP', 'to survive')], [('VP', 'survive')]]\n",
      "204 [[('VP', 'will survive as there is a killer amongst them')], [('VP', 'survive as there is a killer amongst them')]]\n",
      "248 [[('VP', 'must summon the strength to survive and escape the maniac bloodbath')], [('VP', 'summon the strength to survive and escape the maniac bloodbath')], [('VP', 'to survive and escape the maniac bloodbath')], [('VP', 'survive and escape the maniac bloodbath')]]\n",
      "306 [[('VP', 'are attempting to make their escape to Chicago to survive')], [('VP', 'attempting to make their escape to Chicago to survive')], [('VP', 'to make their escape to Chicago to survive')], [('VP', 'make their escape to Chicago to survive')], [('VP', 'to survive')], [('VP', 'survive')]]\n",
      "309 [[('VP', 'survive the terror that has befallen them')]]\n",
      "320 [[('VP', 'will survive this')], [('VP', 'survive this')]]\n",
      "329 [[('VP', 'is growing evidence that vampires deprived of an adequate blood supply are themselves evolving into wild , vile creatures that attack anyone and anything in order to survive')], [('VP', 'growing evidence that vampires deprived of an adequate blood supply are themselves evolving into wild , vile creatures that attack anyone and anything in order to survive')], [('VP', 'are themselves evolving into wild , vile creatures that attack anyone and anything in order to survive')], [('VP', 'evolving into wild , vile creatures that attack anyone and anything in order to survive')], [('VP', 'to survive')], [('VP', 'survive')]]\n",
      "385 [[('VP', 'survive')]]\n"
     ]
    }
   ],
   "source": [
    "findRelation(horrorTree, 'VP', 'survive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "findSubrelation(horrorTree, 'VP', 'RB', 'survive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, according to parsing, we have discovered many interesting findings from the corpora. Extracting nouns related to adjective 'mad', we have proved our previous finding that males are more associated with crazy or lunatic as 'mad' is directly associated to 'man'. It is also interesting to see that 'mad' is also associated with 'antidote' which implies the desire to get rid of this label. From identifying verbs that are related to nouns \"he\" and \"she\", we are also to detect the power dynamics and gender differences that are protrayed in the films as males to be more decisive, smart, and powerful than woman."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information extraction\n",
    "\n",
    "Information extraction approaches typically (as here, with Stanford's Open IE engine) ride atop the dependency parse of a sentence. They are a pre-coded example of the type analyzed in the prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 10.655 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [12.0 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator natlog\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n",
      "[main] INFO edu.stanford.nlp.naturalli.ClauseSplitter - Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0070 seconds]\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - Processing file: /var/folders/cj/kf_cjd3n1tg18chl156k0tfm0000gn/T/tmpzfa9lxoo\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - All files have been queued; awaiting termination...\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - DONE processing files. 0 exceptions encountered.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ieDF = stanford.openIE(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`openIE()` prints everything stanford core produces and we can see from looking at it that initializing the dependency parser takes most of the time, so calling the function will always take at least 12 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I saw the elephant in my pajamas.',\n",
       " 'The quick brown fox jumped over the lazy dog.',\n",
       " 'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.',\n",
       " 'Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.',\n",
       " 'Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo']"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>elephant</td>\n",
       "      <td>is in</td>\n",
       "      <td>my pajamas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>saw</td>\n",
       "      <td>elephant in my pajamas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>saw</td>\n",
       "      <td>elephant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in interview with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in recent interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed stimulus efforts in</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in recent intervie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in recent interview with Wall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in recent interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>short-term stimulus efforts</td>\n",
       "      <td>is in</td>\n",
       "      <td>recent interview with Wall Street Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in interview with Wall Street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>recent interview</td>\n",
       "      <td>is with</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was African American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African American</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    certainty                      subject                           verb  \\\n",
       "0         1.0                     elephant                          is in   \n",
       "1         1.0                            I                            saw   \n",
       "2         1.0                            I                            saw   \n",
       "3         1.0              quick brown fox                    jumped over   \n",
       "4         1.0              quick brown fox                    jumped over   \n",
       "5         1.0                    quick fox                    jumped over   \n",
       "6         1.0                          fox                    jumped over   \n",
       "7         1.0                    brown fox                    jumped over   \n",
       "8         1.0                    brown fox                    jumped over   \n",
       "9         1.0                    quick fox                    jumped over   \n",
       "10        1.0                          fox                    jumped over   \n",
       "11        1.0            Christine Lagarde                      discussed   \n",
       "12        1.0            Christine Lagarde                      discussed   \n",
       "13        1.0            Christine Lagarde                      discussed   \n",
       "14        1.0            Christine Lagarde  discussed stimulus efforts in   \n",
       "15        1.0            Christine Lagarde                      discussed   \n",
       "16        1.0            Christine Lagarde                      discussed   \n",
       "17        1.0            Christine Lagarde                      discussed   \n",
       "18        1.0  short-term stimulus efforts                          is in   \n",
       "19        1.0            Christine Lagarde                      discussed   \n",
       "20        1.0            Christine Lagarde                      discussed   \n",
       "21        1.0            Christine Lagarde                      discussed   \n",
       "22        1.0            Christine Lagarde                      discussed   \n",
       "23        1.0             recent interview                        is with   \n",
       "24        1.0                       Martin                            was   \n",
       "25        1.0      Trayvon Benjamin Martin      was African American from   \n",
       "26        1.0      Trayvon Benjamin Martin              was American from   \n",
       "27        1.0      Trayvon Benjamin Martin                            was   \n",
       "28        1.0      Trayvon Benjamin Martin                            was   \n",
       "\n",
       "                                               object  \n",
       "0                                          my pajamas  \n",
       "1                              elephant in my pajamas  \n",
       "2                                            elephant  \n",
       "3                                            lazy dog  \n",
       "4                                                 dog  \n",
       "5                                                 dog  \n",
       "6                                                 dog  \n",
       "7                                            lazy dog  \n",
       "8                                                 dog  \n",
       "9                                            lazy dog  \n",
       "10                                           lazy dog  \n",
       "11  short-term stimulus efforts in interview with ...  \n",
       "12                      stimulus efforts in interview  \n",
       "13               stimulus efforts in recent interview  \n",
       "14                                             France  \n",
       "15  short-term stimulus efforts in recent intervie...  \n",
       "16  stimulus efforts in recent interview with Wall...  \n",
       "17    short-term stimulus efforts in recent interview  \n",
       "18          recent interview with Wall Street Journal  \n",
       "19  stimulus efforts in interview with Wall Street...  \n",
       "20                                   stimulus efforts  \n",
       "21                        short-term stimulus efforts  \n",
       "22           short-term stimulus efforts in interview  \n",
       "23                                Wall Street Journal  \n",
       "24                                            African  \n",
       "25                                            Florida  \n",
       "26                                            Florida  \n",
       "27                                           American  \n",
       "28                                   African American  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No buffalos (because there were no verbs), but the rest is somewhat promising. Note, however, that it abandoned the key theme of the sentence about the tragic Trayvon Martin death (\"fatally shot\"), likely because it was buried so deeply within the complex phrase structure. This is obviously a challenge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 4*</span>\n",
    "\n",
    "<span style=\"color:red\">How would you extract relevant information about the Trayvon Martin sentence directly from the dependency parse (above)? Code an example here. (For instance, what compound nouns show up with what verb phrases within the sentence?) How could these approaches inform your research project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First take the Trayvon Martin sentence from the text and get a comprehensive view of the raw text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.'"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract relevant information about the Trayvon Martin sentence directly from the dependency parse (above) by slicing the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was African American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African American</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    certainty                  subject                       verb  \\\n",
       "24        1.0                   Martin                        was   \n",
       "25        1.0  Trayvon Benjamin Martin  was African American from   \n",
       "26        1.0  Trayvon Benjamin Martin          was American from   \n",
       "27        1.0  Trayvon Benjamin Martin                        was   \n",
       "28        1.0  Trayvon Benjamin Martin                        was   \n",
       "\n",
       "              object  \n",
       "24           African  \n",
       "25           Florida  \n",
       "26           Florida  \n",
       "27          American  \n",
       "28  African American  "
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF.iloc[24:29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It could be seen from the table above that the original sentence has way more information than the current parser has deciphered, meaning dependency parser did not extract the full information from that sentence. Also, it is obvious that the dependency parser only included information up until the second comma, all the rest of the information \" who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.\" is lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to include the complete sentence into the analysis, I would manually create a new sentence that is only consisted of the second part of sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TBM = \"who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, extract relevant information on part of the Trayvon Martin sentence that was overlooked by the parser when put into the parser in a complete sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 11.249 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [12.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator natlog\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n",
      "[main] INFO edu.stanford.nlp.naturalli.ClauseSplitter - Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0070 seconds]\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - Processing file: /var/folders/cj/kf_cjd3n1tg18chl156k0tfm0000gn/T/tmpsuv3qeri\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - No extractions in: /var/folders/cj/kf_cjd3n1tg18chl156k0tfm0000gn/T/tmpsuv3qeri\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - All files have been queued; awaiting termination...\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - DONE processing files. 0 exceptions encountered.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [certainty, subject, verb, object]\n",
       "Index: []"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanford.openIE(TBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is weird that the parser fails to read all text information. Now I suspect its the problem of comma. So, remove all comma to see if it would imporve the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trayvon Benjamin Martin was an African American from Miami Gardens Florida who at 17 years old was fatally shot by George Zimmerman a neighborhood watch volunteer in Sanford Florida.'"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "TBM_noComma = re.sub(',', '', text[3])\n",
    "TBM_noComma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send the processed text to the dependency parser again to see if there is any improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 9.352 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [10.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator natlog\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n",
      "[main] INFO edu.stanford.nlp.naturalli.ClauseSplitter - Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0064 seconds]\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - Processing file: /var/folders/cj/kf_cjd3n1tg18chl156k0tfm0000gn/T/tmpdp9xl0zh\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - All files have been queued; awaiting termination...\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - DONE processing files. 0 exceptions encountered.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>neighborhood watch volunteer</td>\n",
       "      <td>is in</td>\n",
       "      <td>Sanford Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   certainty                       subject   verb           object\n",
       "0        1.0  neighborhood watch volunteer  is in  Sanford Florida\n",
       "1        1.0                        Martin    was          African"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanford.openIE(TBM_noComma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the commas, the results is improved as it included the complete and comprehensive of the whole sentence. I think this is a wonderful experience that informaing me that punctuation could potentially be a confounding factors influencing the dependency parser when processing raw text. I think it would be a good practice to get rid of all punctuations before sending it to the parser for a comprehensive review of the sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also look for subject, object, target triples in one of the reddit stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ieDF = stanford.openIE(redditTopScores['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ieDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's almost 200 triples in only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(redditTopScores['sentences'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentences and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum([len(s) for s in redditTopScores['sentences'][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find at the most common subject in this story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ieDF['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I is followed by various male pronouns and compound nouns (e.g., \"old man\"). 'I' occures most often with the following verbs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ieDF[ieDF['subject'] == 'I']['verb'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the following objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ieDF[ieDF['subject'] == 'I']['object'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run the corenlp server. When you run this server (with the command below), you can click on the browswer link provided to experiment with it. Note that when we run the server, executing the command below, it interrupts the current jupyter process and you will not be able to run code here again (processes will \"hang\" and never finish) until you interrup the process by clicking \"Kernel\" and then \"Interrupt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stanford.startCoreServer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <span style=\"color:red\">*Exercise 5*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform open information extraction on a modest subset of texts relevant to your final project. Analyze the relative attachment of several subjects relative to verbs and objects and visa versa. Describe how you would select among these statements to create a database of high-value statements for your project and then do it by extracting relevant statements into a pandas dataframe."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
